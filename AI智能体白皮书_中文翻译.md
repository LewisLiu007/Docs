# 智能体 (Agents)

**作者：** Julia Wiesinger, Patrick Marlow 和 Vladimir Vuskovic

**发布时间：** 2025年2月

---

## 致谢

### 内容贡献者
- Evan Huang
- Emily Xue
- Olcan Sercinoglu
- Sebastian Riedel
- Satinder Baveja
- Antonio Gulli
- Anant Nawalgaria

### 策划与编辑
- Antonio Gulli
- Anant Nawalgaria
- Grace Mollison

### 技术作者
- Joey Haymaker

### 设计师
- Michael Lanning

---

## 目录

1. [引言](#引言) .......................................................... 4
2. [什么是智能体？](#什么是智能体) ........................................ 5
   - 模型 ............................................................. 6
   - 工具 ............................................................. 7
   - 编排层 ........................................................... 7
   - 智能体 vs. 模型 .................................................. 8
3. [认知架构：智能体如何运作](#认知架构智能体如何运作) .................... 8
4. [工具：通往外部世界的钥匙](#工具通往外部世界的钥匙) ................... 12
   - 扩展 (Extensions) ................................................ 13
   - 扩展示例 ........................................................ 15
   - 函数 (Functions) ................................................. 18
   - 使用场景 ........................................................ 21
   - 函数示例代码 .................................................... 24
   - 数据存储 (Data Stores) ........................................... 27
   - 实现与应用 ...................................................... 28
   - 工具总结 ........................................................ 32
5. [通过针对性学习增强模型性能](#通过针对性学习增强模型性能) ............ 33
6. [使用 LangChain 快速开始智能体开发](#使用langchain快速开始智能体开发) .. 35
7. [使用 Vertex AI 智能体构建生产应用](#使用vertex-ai智能体构建生产应用) . 38
8. [总结](#总结) ....................................................... 40
9. [参考文献](#参考文献) ............................................... 42

---

## 引言

人类在处理复杂的模式识别任务时表现出色。然而，他们通常依赖工具——如书籍、Google搜索或计算器——来补充先验知识，然后才能得出结论。与人类一样，生成式AI模型可以被训练使用工具来访问实时信息或建议实际行动。例如，模型可以利用数据库检索工具访问特定信息（如客户的购买历史），从而生成个性化的购物推荐。或者，基于用户的查询，模型可以进行各种API调用，代表用户向同事发送电子邮件回复或完成金融交易。

为了实现这一点，模型不仅需要访问一组外部工具，还需要具备以自主方式规划和执行任务的能力。这种推理、逻辑和外部信息访问的组合，都连接到生成式AI模型，引出了**智能体 (agent)** 的概念——一个超越生成式AI模型独立能力的程序。

> **核心概念：** 推理、逻辑和外部信息访问的组合，连接到生成式AI模型，构成了智能体的概念。

本白皮书将深入探讨这些内容及相关的各个方面。

---

## 什么是智能体？

从最基本的形式来说，生成式AI智能体可以定义为：**一个通过观察世界并使用其可用工具对世界采取行动来尝试实现目标的应用程序**。

智能体具有自主性，可以独立于人类干预而行动，特别是当为其提供适当的目标或目的时。智能体还可以主动采取措施来实现其目标。即使在没有人类明确指令的情况下，智能体也可以推理下一步应该做什么来实现其最终目标。

虽然AI中的智能体概念非常通用和强大，但本白皮书重点关注生成式AI模型在发布时能够构建的特定类型的智能体。

为了理解智能体的内部工作原理，让我们首先介绍驱动智能体行为、行动和决策的基础组件。这些组件的组合可以描述为**认知架构 (cognitive architecture)**，通过混合和匹配这些组件可以实现许多这样的架构。

专注于核心功能，智能体的认知架构中有三个基本组件，如图1所示。

### 图1. 通用智能体架构和组件
[智能体包含三个核心组件：模型、工具和编排层]

### 模型 (The Model)

在智能体的范围内，模型指的是将用作智能体流程集中决策者的**语言模型 (LM)**。智能体使用的模型可以是一个或多个任意大小（小型/大型）的语言模型，这些模型能够遵循基于指令的推理和逻辑框架，如 ReAct、思维链 (Chain-of-Thought) 或思维树 (Tree-of-Thoughts)。

模型可以是通用的、多模态的，或根据特定智能体架构的需求进行微调的。为了获得最佳的生产结果，您应该选择最适合您期望的最终应用的模型，理想情况下，该模型已在与您计划在认知架构中使用的工具相关的数据特征上进行训练。

重要的是要注意，模型通常不会使用智能体的特定配置设置（即工具选择、编排/推理设置）进行训练。然而，可以通过为模型提供展示智能体能力的示例来进一步优化模型以完成智能体的任务，包括智能体在各种上下文中使用特定工具或推理步骤的实例。

### 工具 (The Tools)

基础模型尽管在文本和图像生成方面令人印象深刻，但仍然受到无法与外部世界交互的限制。工具弥合了这一差距，使智能体能够与外部数据和服务交互，同时解锁超出底层模型本身的更广泛的操作范围。

工具可以采取各种形式，并具有不同的复杂程度，但通常与常见的Web API方法（如GET、POST、PATCH和DELETE）保持一致。例如，工具可以更新数据库中的客户信息，或获取天气数据以影响智能体向用户提供的旅行建议。

通过工具，智能体可以访问和处理现实世界的信息。这使它们能够支持更专业的系统，如**检索增强生成 (RAG)**，它显著扩展了智能体的能力，超出了基础模型本身所能实现的范围。

我们将在下文中更详细地讨论工具，但最重要的是要理解，工具在智能体的内部能力和外部世界之间架起了桥梁，开启了更广泛的可能性。

### 编排层 (The Orchestration Layer)

编排层描述了一个循环过程，该过程控制智能体如何接收信息、执行一些内部推理，并使用该推理来指导其下一步行动或决策。通常，这个循环将持续到智能体达到其目标或停止点为止。

编排层的复杂性可以根据智能体及其执行的任务而有很大差异。一些循环可以是简单的计算和决策规则，而其他循环可能包含链式逻辑、涉及额外的机器学习算法或实现其他概率推理技术。

我们将在认知架构部分更详细地讨论智能体编排层的详细实现。

---

## 智能体 vs. 模型

为了更清楚地理解智能体和模型之间的区别，请考虑以下对比表：

| **模型 (Models)** | **智能体 (Agents)** |
|------------------|---------------------|
| 知识仅限于训练数据中可用的内容 | 通过工具连接外部系统来扩展知识 |
| 基于用户查询的单次推理/预测。除非明确为模型实现，否则没有会话历史或连续上下文的管理（即聊天历史） | 管理会话历史（即聊天历史），允许基于用户查询和编排层中做出的决策进行多轮推理/预测。在此上下文中，"轮次"定义为交互系统与智能体之间的交互（即1个传入事件/查询和1个智能体响应） |
| 没有原生工具实现 | 工具原生实现在智能体架构中 |
| 没有实现原生逻辑层。用户可以将提示形成简单问题或使用推理框架（CoT、ReAct等）形成复杂提示来指导模型进行预测 | 使用推理框架（如CoT、ReAct）或其他预构建的智能体框架（如LangChain）的原生认知架构 |

---

## 认知架构：智能体如何运作

想象一位在繁忙厨房中的厨师。他们的目标是为餐厅顾客创造美味的菜肴，这涉及规划、执行和调整的循环：

- 他们收集信息，如顾客的订单以及储藏室和冰箱里有什么食材
- 他们根据刚刚收集的信息进行一些内部推理，思考可以创造什么菜肴和风味组合
- 他们采取行动来制作菜肴：切蔬菜、混合香料、煎肉

在过程的每个阶段，厨师根据需要进行调整，随着食材的消耗或收到顾客反馈而完善计划，并使用之前的结果来确定下一个行动计划。这种信息摄入、规划、执行和调整的循环描述了厨师用来实现目标的独特认知架构。

与厨师一样，智能体可以使用认知架构通过迭代处理信息、做出明智的决策以及基于先前输出完善下一步行动来实现最终目标。

智能体认知架构的核心是**编排层**，负责维护记忆、状态、推理和规划。它使用快速发展的提示工程领域和相关框架来指导推理和规划，使智能体能够更有效地与其环境交互并完成任务。

语言模型的提示工程框架和任务规划领域的研究正在快速发展，产生了各种有前景的方法。虽然不是详尽的列表，但以下是本出版物发布时一些最流行的框架和推理技术：

### 主要推理框架

1. **ReAct** - 一种提示工程框架，为语言模型提供思维过程策略，以对用户查询进行推理和采取行动，可以带有或不带上下文示例。ReAct提示已显示出超越多个SOTA基线的性能，并提高了LLM的人类互操作性和可信度。

2. **思维链 (Chain-of-Thought, CoT)** - 一种通过中间步骤启用推理能力的提示工程框架。CoT有各种子技术，包括自一致性、主动提示和多模态CoT，每种技术根据具体应用都有其优缺点。

3. **思维树 (Tree-of-Thoughts, ToT)** - 一种非常适合探索或战略前瞻任务的提示工程框架。它概括了思维链提示，允许模型探索各种思维链，这些思维链作为语言模型通用问题解决的中间步骤。

智能体可以利用上述推理技术之一或许多其他技术来选择给定用户请求的下一个最佳行动。

### ReAct 框架示例

例如，让我们考虑一个被编程使用ReAct框架来选择正确行动和工具的智能体。事件序列可能如下所示：

1. 用户向智能体发送查询
2. 智能体开始ReAct序列
3. 智能体向模型提供提示，要求它生成下一个ReAct步骤及其相应的输出：
   - **Question（问题）**：来自用户查询的输入问题，随提示一起提供
   - **Thought（思考）**：模型关于下一步应该做什么的想法
   - **Action（行动）**：模型关于下一步采取什么行动的决定
     - 这是工具选择可能发生的地方
     - 例如，行动可以是 [Flights, Search, Code, None] 之一，其中前3个代表模型可以选择的已知工具，最后一个代表"无工具选择"
   - **Action Input（行动输入）**：模型关于向工具提供什么输入的决定（如果有）
   - **Observation（观察）**：行动/行动输入序列的结果
     - 这个思考/行动/行动输入/观察可以根据需要重复N次
   - **Final Answer（最终答案）**：模型为原始用户查询提供的最终答案
4. ReAct循环结束，并向用户提供最终答案

### 图2. 在编排层中使用ReAct推理的示例智能体
[显示用户查询 → 智能体推理 → 工具调用 → 最终响应的流程]

如图2所示，模型、工具和智能体配置协同工作，根据用户的原始查询向用户提供有根据的简洁响应。虽然模型可以根据其先验知识猜测答案（产生幻觉），但它反而使用了一个工具（Flights）来搜索实时外部信息。这些额外的信息被提供给模型，使其能够基于真实事实数据做出更明智的决策，并将这些信息总结回给用户。

**总结：** 智能体响应的质量可以直接与模型推理和处理这些各种任务的能力相关联，包括选择正确工具的能力，以及工具定义的好坏。就像厨师使用新鲜食材并关注顾客反馈来制作菜肴一样，智能体依赖于良好的推理和可靠的信息来提供最佳结果。

在下一节中，我们将深入探讨智能体连接新鲜数据的各种方式。

---

## 工具：通往外部世界的钥匙

虽然语言模型擅长处理信息，但它们缺乏直接感知和影响现实世界的能力。这限制了它们在需要与外部系统或数据交互的情况下的实用性。这意味着，从某种意义上说，语言模型的好坏取决于它从训练数据中学到的东西。

但无论我们向模型投入多少数据，它们仍然缺乏与外部世界交互的基本能力。那么，我们如何赋予模型与外部系统进行实时、上下文感知交互的能力呢？

**函数 (Functions)、扩展 (Extensions)、数据存储 (Data Stores) 和插件 (Plugins)** 都是为模型提供这一关键能力的方式。

虽然它们有很多名称，但**工具 (Tools)** 是在我们的基础模型和外部世界之间创建链接的东西。这种与外部系统和数据的链接使我们的智能体能够执行更广泛的任务，并以更高的准确性和可靠性执行。例如，工具可以使智能体调整智能家居设置、更新日历、从数据库获取用户信息或根据特定指令集发送电子邮件。

截至本出版物发布之日，Google模型能够交互的主要有三种工具类型：**扩展 (Extensions)、函数 (Functions) 和数据存储 (Data Stores)**。

通过为智能体配备工具，我们释放了它们不仅理解世界而且对其采取行动的巨大潜力，为无数新应用和可能性打开了大门。

---

## 扩展 (Extensions)

理解扩展的最简单方法是将它们视为以标准化方式在API和智能体之间架起桥梁，允许智能体无缝执行API，无论其底层实现如何。

假设您已经构建了一个目标是帮助用户预订航班的智能体。您知道要使用Google Flights API来检索航班信息，但不确定如何让智能体调用此API端点。

### 图3. 智能体如何与外部API交互？
[显示智能体和API之间的连接问题]

一种方法是实现自定义代码，该代码将接收传入的用户查询，解析查询以获取相关信息，然后进行API调用。例如，在航班预订用例中，用户可能会说"我想预订从奥斯汀到苏黎世的航班"。在这种情况下，我们的自定义代码解决方案需要从用户查询中提取"奥斯汀"和"苏黎世"作为相关实体，然后再尝试进行API调用。

但是，如果用户说"我想预订到苏黎世的航班"而从未提供出发城市会怎样？如果没有所需数据，API调用将失败，需要实现更多代码来捕获这样的边缘和角落情况。这种方法不可扩展，并且很容易在任何超出已实现自定义代码的情况下出现故障。

### 更具弹性的方法：使用扩展

扩展通过以下方式在智能体和API之间架起桥梁：

1. 使用示例教智能体如何使用API端点
2. 教智能体成功调用API端点所需的参数或参数

### 图4. 扩展将智能体连接到外部API
[显示扩展作为中间层的架构]

扩展可以独立于智能体创建，但应作为智能体配置的一部分提供。智能体在运行时使用模型和示例来决定哪个扩展（如果有）适合解决用户的查询。这突出了扩展的一个关键优势，即它们的内置示例类型，允许智能体动态选择最适合任务的扩展。

### 图5. 智能体、扩展和API之间的一对多关系
[显示一个智能体可以使用多个扩展]

将此视为与软件开发人员在解决用户问题时决定使用哪些API端点的方式相同。如果用户想预订航班，开发人员可能会使用Google Flights API。如果用户想知道离他们位置最近的咖啡店在哪里，开发人员可能会使用Google Maps API。

以同样的方式，智能体/模型堆栈使用一组已知的扩展来决定哪一个最适合用户的查询。

### 试用扩展

如果您想看到扩展的实际应用，可以在Gemini应用程序上试用它们，方法是转到设置 > 扩展，然后启用您想要测试的任何扩展。例如，您可以启用Google Flights扩展，然后询问Gemini"显示下周五从奥斯汀到苏黎世的航班"。

---

## 扩展示例

为了简化扩展的使用，Google提供了一些开箱即用的扩展，可以快速导入到您的项目中并以最少的配置使用。

### 示例：代码解释器扩展

例如，代码片段1中的**代码解释器 (Code Interpreter)** 扩展允许您从自然语言描述生成和运行Python代码。

```python
import vertexai
import pprint

PROJECT_ID = "YOUR_PROJECT_ID"
REGION = "us-central1"
vertexai.init(project=PROJECT_ID, location=REGION)

from vertexai.preview.extensions import Extension
extension_code_interpreter = Extension.from_hub("code_interpreter")

CODE_QUERY = """Write a python method to invert a binary tree in O(n) time."""

response = extension_code_interpreter.execute(
    operation_id = "generate_and_execute",
    operation_params = {"query": CODE_QUERY}
)

print("Generated Code:")
pprint.pprint({response['generated_code']})
```

**生成的代码：**

```python
class TreeNode:
    def __init__(self, val=0, left=None, right=None):
        self.val = val
        self.left = left
        self.right = right

def invert_binary_tree(root):
    """
    反转二叉树。
    参数:
        root: 二叉树的根节点。
    返回:
        反转后的二叉树的根节点。
    """
    if not root:
        return None
    
    # 递归交换左右子节点
    root.left, root.right = invert_binary_tree(root.right), invert_binary_tree(root.left)
    return root

# 示例使用：
# 构建示例二叉树
root = TreeNode(4)
root.left = TreeNode(2)
root.right = TreeNode(7)
root.left.left = TreeNode(1)
root.left.right = TreeNode(3)
root.right.left = TreeNode(6)
root.right.right = TreeNode(9)

# 反转二叉树
inverted_root = invert_binary_tree(root)
```

**代码片段1.** 代码解释器扩展可以生成和运行Python代码

**总结：** 扩展为智能体提供了以无数方式感知、交互和影响外部世界的途径。这些扩展的选择和调用由示例的使用指导，所有这些都作为扩展配置的一部分定义。

---

## 函数 (Functions)

在软件工程领域，函数被定义为完成特定任务并可根据需要重用的自包含代码模块。当软件开发人员编写程序时，他们通常会创建许多函数来执行各种任务。他们还将定义何时调用function_a与function_b的逻辑，以及预期的输入和输出。

函数在智能体世界中的工作方式非常相似，但我们可以用模型替换软件开发人员。模型可以接受一组已知函数，并根据其规范决定何时使用每个函数以及函数需要什么参数。

### 函数与扩展的区别

函数在几个方面与扩展不同，最值得注意的是：

1. **模型输出函数及其参数，但不进行实时API调用**
2. **函数在客户端执行，而扩展在智能体端执行**

### 图7. 函数如何与外部API交互？
[显示函数调用的架构]

请注意，这里的主要区别是函数和智能体都不直接与Google Flights API交互。那么API调用实际上是如何发生的呢？

使用函数时，调用实际API端点的逻辑和执行从智能体卸载回客户端应用程序，如下图8和图9所示。这为开发人员提供了对应用程序中数据流的更精细控制。

### 开发人员可能选择使用函数而不是扩展的原因

- API调用需要在应用程序堆栈的另一层进行，在直接智能体架构流之外（例如中间件系统、前端框架等）
- 安全或身份验证限制阻止智能体直接调用API（例如API未暴露到互联网，或智能体基础设施无法访问）
- 时间或操作顺序约束阻止智能体实时进行API调用（即批处理操作、人工参与审查等）
- 需要对API响应应用额外的数据转换逻辑，而智能体无法执行。例如，考虑一个不提供过滤机制来限制返回结果数量的API端点。在客户端使用函数为开发人员提供了进行这些转换的额外机会
- 开发人员希望在不为API端点部署额外基础设施的情况下迭代智能体开发（即函数调用可以像API的"存根"一样工作）

虽然两种方法之间的内部架构差异很微妙（如图8所示），但对外部基础设施的额外控制和解耦依赖使函数调用成为开发人员的一个有吸引力的选择。

### 图8. 划分扩展和函数调用的客户端与智能体端控制
[显示控制流的比较]

---

## 函数使用场景

模型可以用于调用函数，以便为最终用户处理复杂的客户端执行流程，在这种情况下，智能体开发人员可能不希望语言模型管理API执行（扩展就是这种情况）。

### 旅行顾问示例

让我们考虑以下示例，其中智能体被训练为旅行顾问，与想要预订度假旅行的用户进行交互。目标是让智能体生成一个城市列表，我们可以在中间件应用程序中使用该列表下载图像、数据等，用于用户的旅行规划。

用户可能会说：

> "我想和家人一起去滑雪，但我不确定去哪里。"

在对模型的典型提示中，输出可能如下所示：

> 当然，这里有一些您可以考虑的家庭滑雪旅行城市列表：
> - 科罗拉多州克雷斯特德比特，美国
> - 不列颠哥伦比亚省惠斯勒，加拿大
> - 瑞士采尔马特

虽然上述输出包含我们需要的数据（城市名称），但格式不适合解析。使用函数调用，我们可以教模型以结构化样式（如JSON）格式化此输出，这对其他系统解析更方便。

给定来自用户的相同输入提示，函数的示例JSON输出可能如下所示：

```json
function_call {
  name: "display_cities"
  args: {
    "cities": ["Crested Butte", "Whistler", "Zermatt"],
    "preferences": "skiing"
  }
}
```

**代码片段5.** 用于显示城市列表和用户偏好的示例函数调用负载

此JSON负载由模型生成，然后发送到我们的客户端服务器，以便我们可以随意处理它。在这种特定情况下，我们将调用Google Places API，获取模型提供的城市并查找图像，然后将它们作为格式化的丰富内容提供回我们的用户。

### 图9. 显示函数调用生命周期的序列图
[显示详细的交互流程]

图9中示例的结果是，模型被用来"填空"，提供客户端UI调用Google Places API所需的参数。客户端UI使用模型在返回的函数中提供的参数管理实际的API调用。

### 函数调用的其他使用场景

- 您希望语言模型建议可以在代码中使用的函数，但不想在代码中包含凭据。因为函数调用不运行函数，所以您不需要在代码中包含带有函数信息的凭据
- 您正在运行可能需要几秒钟以上的异步操作。这些场景很适合函数调用，因为它是异步操作
- 您希望在与生成函数调用及其参数的系统不同的设备上运行函数

### 关键要点

关于函数要记住的一件关键事情是，它们旨在为开发人员提供对API调用执行以及整个应用程序中数据流的更多控制。在图9的示例中，开发人员选择不将API信息返回给智能体，因为它与智能体可能采取的未来行动无关。

然而，根据应用程序的架构，将外部API调用数据返回给智能体可能是有意义的，以便影响未来的推理、逻辑和行动选择。最终，由应用程序开发人员选择适合特定应用程序的方案。

---

## 函数示例代码

为了从我们的滑雪度假场景中获得上述输出，让我们构建每个组件，使其与我们的 `gemini-2.0-flash-001` 模型一起工作。

首先，我们将 `display_cities` 函数定义为一个简单的Python方法：

```python
from typing import Optional

def display_cities(cities: list[str], preferences: Optional[str] = None):
    """根据用户的搜索查询和偏好提供城市列表。
    
    参数:
        preferences (str): 用户对搜索的偏好，如滑雪、
            海滩、餐厅、烧烤等。
        cities (list[str]): 向用户推荐的城市列表。
    
    返回:
        list[str]: 向用户推荐的城市列表。
    """
    return cities
```

**代码片段6.** 用于显示城市列表的函数的示例Python方法

接下来，我们将实例化我们的模型，构建工具，然后将用户的查询和工具传递给模型：

```python
from google.genai import Client, types

client = Client(
    vertexai=True,
    project="PROJECT_ID",
    location="us-central1"
)

res = client.models.generate_content(
    model="gemini-2.0-flash-001",
    contents="I'd like to take a ski trip with my family but I'm not sure where to go?",
    config=types.GenerateContentConfig(
        tools=[display_cities],
        automatic_function_calling=types.AutomaticFunctionCallingConfig(disable=True),
        tool_config=types.ToolConfig(
            function_calling_config=types.FunctionCallingConfig(mode='ANY')
        )
    )
)

print(f"Function Name: {res.candidates[0].content.parts[0].function_call.name}")
print(f"Function Args: {res.candidates[0].content.parts[0].function_call.args}")

# 输出:
# Function Name: display_cities
# Function Args: {'preferences': 'skiing', 'cities': ['Aspen', 'Park City', 'Whistler']}
```

**代码片段7.** 构建工具，将其与用户查询一起发送到模型并允许函数调用

**总结：** 函数提供了一个直接的框架，使应用程序开发人员能够对数据流和系统执行进行细粒度控制，同时有效地利用智能体/模型进行关键输入生成。开发人员可以根据特定的应用程序架构要求，选择性地选择是否通过返回外部数据来保持智能体"在循环中"，或者省略它。

---

## 数据存储 (Data Stores)

想象一个语言模型就像一个巨大的图书馆，包含其训练数据。但与不断获取新书的图书馆不同，这个图书馆保持静态，只保存最初训练时的知识。这带来了挑战，因为现实世界的知识在不断发展。

**数据存储** 通过提供对更动态和最新信息的访问来解决这一限制，并确保模型的响应保持基于事实和相关性。

### 图10. 智能体如何与结构化和非结构化数据交互？
[显示数据存储连接]

考虑一个常见场景，开发人员可能需要向模型提供少量额外数据，可能以电子表格或PDF的形式。

数据存储允许开发人员以原始格式向智能体提供额外数据，消除了耗时的数据转换、模型重新训练或微调的需要。数据存储将传入文档转换为一组向量数据库嵌入，智能体可以使用这些嵌入来提取所需的信息，以补充其下一步行动或对用户的响应。

### 图11. 数据存储将智能体连接到各种类型的新实时数据源
[显示多种数据源类型]

---

## 数据存储的实现与应用

在生成式AI智能体的上下文中，数据存储通常实现为开发人员希望智能体在运行时访问的向量数据库。虽然我们不会在这里深入讨论向量数据库，但要理解的关键点是，它们以向量嵌入的形式存储数据，向量嵌入是所提供数据的一种高维向量或数学表示。

### 检索增强生成 (RAG)

近年来，数据存储与语言模型一起使用的最多产的示例之一是**检索增强生成 (RAG)** 应用程序的实现。这些应用程序试图通过让模型访问各种格式的数据来扩展模型知识的广度和深度，超出基础训练数据：

- **网站内容**
- **结构化数据**：PDF、Word文档、CSV、电子表格等格式
- **非结构化数据**：HTML、PDF、TXT等格式

### 图12. 智能体与数据存储之间的一对多关系，可以表示各种类型的预索引数据
[显示多个数据存储连接]

每个用户请求和智能体响应循环的底层过程通常建模如图13所示：

1. 用户查询被发送到嵌入模型以生成查询的嵌入
2. 然后使用匹配算法（如ScaNN）将查询嵌入与向量数据库的内容进行匹配
3. 从向量数据库中以文本格式检索匹配的内容并发送回智能体
4. 智能体接收用户查询和检索的内容，然后制定响应或行动
5. 向用户发送最终响应

### 图13. RAG应用程序中用户请求和智能体响应的生命周期
[显示RAG流程图]

最终结果是一个应用程序，允许智能体通过向量搜索将用户的查询与已知数据存储匹配，检索原始内容，并将其提供给编排层和模型进行进一步处理。下一步行动可能是向用户提供最终答案，或执行额外的向量搜索以进一步完善结果。

### 图14. 使用ReAct推理/规划的示例RAG应用程序
[显示完整的RAG交互示例]

---

## 工具总结

总而言之，扩展、函数和数据存储构成了智能体在运行时可以使用的几种不同工具类型。每种工具都有其自己的目的，它们可以根据智能体开发人员的判断一起使用或独立使用。

| **特性** | **扩展 (Extensions)** | **函数调用 (Function Calling)** | **数据存储 (Data Stores)** |
|---------|---------------------|-------------------------------|--------------------------|
| **执行** | 智能体端执行 | 客户端执行 | 智能体端执行 |
| **使用场景** | • 开发人员希望智能体控制与API端点的交互<br>• 在利用原生预构建扩展时很有用（即Vertex Search、代码解释器等）<br>• 多跳规划和API调用（即下一个智能体操作取决于先前操作/API调用的输出） | • 安全或身份验证限制阻止智能体直接调用API<br>• 时间约束或操作顺序约束阻止智能体实时进行API调用（即批处理操作、人工参与审查等）<br>• 未暴露到互联网的API，或Google系统无法访问的API | 开发人员希望使用以下任何数据类型实现检索增强生成(RAG)：<br>• 来自预索引域和URL的网站内容<br>• PDF、Word文档、CSV、电子表格等格式的结构化数据<br>• 关系/非关系数据库<br>• HTML、PDF、TXT等格式的非结构化数据 |

---

## 通过针对性学习增强模型性能

有效使用模型的一个关键方面是它们在生成输出时选择正确工具的能力，特别是在生产中大规模使用工具时。虽然通用训练有助于模型发展这项技能，但现实世界的场景通常需要超出训练数据的知识。

将此想象为基本烹饪技能与掌握特定菜系之间的区别。两者都需要基础烹饪知识，但后者需要针对性学习以获得更细腻的结果。

### 针对性学习方法

为了帮助模型获得这种特定知识的访问权限，存在几种方法：

1. **上下文学习 (In-context learning)**
   - 此方法在推理时为通用模型提供提示、工具和少样本示例，允许它"即时"学习如何以及何时使用这些工具来完成特定任务
   - ReAct框架是这种方法在自然语言中的一个示例

2. **基于检索的上下文学习 (Retrieval-based in-context learning)**
   - 此技术通过从外部记忆中检索最相关的信息、工具和相关示例来动态填充模型提示
   - 一个例子是Vertex AI扩展中的"示例存储"或前面提到的基于RAG的数据存储架构

3. **基于微调的学习 (Fine-tuning based learning)**
   - 此方法涉及在推理之前使用更大的特定示例数据集训练模型
   - 这有助于模型在接收任何用户查询之前了解何时以及如何应用某些工具

### 烹饪类比

为了提供对每种针对性学习方法的额外见解，让我们重新审视我们的烹饪类比：

- **上下文学习**：想象一位厨师从顾客那里收到了特定的食谱（提示）、一些关键食材（相关工具）和一些示例菜肴（少样本示例）。基于这些有限的信息和厨师的一般烹饪知识，他们需要"即时"弄清楚如何准备最符合食谱和顾客偏好的菜肴。

- **基于检索的上下文学习**：现在让我们想象我们的厨师在一个有储备充足的食品储藏室（外部数据存储）的厨房里，里面装满了各种食材和食谱书（示例和工具）。厨师现在能够从食品储藏室动态选择食材和食谱书，更好地符合顾客的食谱和偏好。这使厨师能够利用现有和新知识创造更明智和精致的菜肴。

- **基于微调的学习**：最后，让我们想象我们把厨师送回学校学习新的菜系或一组菜系（在更大的特定示例数据集上进行预训练）。这使厨师能够以更深入的理解来处理未来未见过的顾客食谱。如果我们希望厨师在特定菜系（知识领域）中表现出色，这种方法是完美的。

每种方法在速度、成本和延迟方面都提供独特的优势和劣势。然而，通过在智能体框架中结合这些技术，我们可以利用各种优势并最小化它们的弱点，从而实现更强大和适应性更强的解决方案。

---

## 使用 LangChain 快速开始智能体开发

为了提供智能体实际运行的真实可执行示例，我们将使用LangChain和LangGraph库构建一个快速原型。这些流行的开源库允许用户通过将逻辑、推理和工具调用的序列"链接"在一起来构建客户智能体，以回答用户的查询。

我们将使用 `gemini-2.0-flash-001` 模型和一些简单的工具来回答用户的多阶段查询，如代码片段8所示。

我们使用的工具是SerpAPI（用于Google搜索）和Google Places API。执行代码片段8中的程序后，您可以在代码片段9中看到示例输出。

```python
from langgraph.prebuilt import create_react_agent
from langchain_core.tools import tool
from langchain_community.utilities import SerpAPIWrapper
from langchain_community.tools import GooglePlacesTool

os.environ["SERPAPI_API_KEY"] = "XXXXX"
os.environ["GPLACES_API_KEY"] = "XXXXX"

@tool
def search(query: str):
    """使用SerpAPI运行Google搜索。"""
    search = SerpAPIWrapper()
    return search.run(query)

@tool
def places(query: str):
    """使用Google Places API运行Google Places查询。"""
    places = GooglePlacesTool()
    return places.run(query)

model = ChatVertexAI(model="gemini-2.0-flash-001")
tools = [search, places]

query = "Who did the Texas Longhorns play in football last week? What is the address of the other team's stadium?"

agent = create_react_agent(model, tools)
input = {"messages": [("human", query)]}

for s in agent.stream(input, stream_mode="values"):
    message = s["messages"][-1]
    if isinstance(message, tuple):
        print(message)
    else:
        message.pretty_print()
```

**代码片段8.** 使用工具的示例LangChain和LangGraph智能体

### 输出结果

```
============================== Human Message ================================
Who did the Texas Longhorns play in football last week? What is the address 
of the other team's stadium?

================================= Ai Message =================================
Tool Calls: search
Args:
   query: Texas Longhorns football schedule

================================ Tool Message ================================
Name: search
{...Results: "NCAA Division I Football, Georgia, Date..."}

================================= Ai Message =================================
The Texas Longhorns played the Georgia Bulldogs last week.
Tool Calls: places
Args:
   query: Georgia Bulldogs stadium

================================ Tool Message ================================
Name: places
{...Sanford Stadium Address: 100 Sanford...}

================================= Ai Message =================================
The address of the Georgia Bulldogs stadium is 100 Sanford Dr, Athens, GA 
30602, USA.
```

**代码片段9.** 来自代码片段8中程序的输出

虽然这是一个相当简单的智能体示例，但它展示了模型、编排和工具的基础组件如何协同工作以实现特定目标。在最后一节中，我们将探讨这些组件如何在Google规模的托管产品（如Vertex AI智能体和生成式Playbook）中结合在一起。

---

## 使用 Vertex AI 智能体构建生产应用

虽然本白皮书探讨了智能体的核心组件，但构建生产级应用程序需要将它们与其他工具集成，如用户界面、评估框架和持续改进机制。

**Google的Vertex AI平台** 通过提供包含前面介绍的所有基本元素的完全托管环境来简化此过程。使用自然语言界面，开发人员可以快速定义智能体的关键元素：

- 目标
- 任务指令
- 工具
- 用于任务委派的子智能体
- 示例

这样可以轻松构建所需的系统行为。

### Vertex AI 平台功能

此外，该平台配备了一套开发工具，允许：

- 测试
- 评估
- 测量智能体性能
- 调试
- 提高已开发智能体的整体质量

这使开发人员能够专注于构建和完善他们的智能体，而基础设施、部署和维护的复杂性由平台本身管理。

### 图15. 在Vertex AI平台上构建的示例端到端智能体架构
[显示完整的生产架构]

在图15中，我们提供了在Vertex AI平台上使用各种功能构建的智能体的示例架构，例如：

- Vertex Agent Builder
- Vertex Extensions
- Vertex Function Calling
- Vertex Example Store

该架构包括生产就绪应用程序所需的许多各种组件。

您可以从我们的官方文档中尝试此预构建智能体架构的示例。

---

## 总结

在本白皮书中，我们讨论了生成式AI智能体的基础构建块、它们的组成以及以认知架构形式实现它们的有效方法。

### 主要要点

1. **智能体扩展语言模型的能力**
   - 通过利用工具访问实时信息、建议现实世界的行动，以及自主规划和执行复杂任务
   - 智能体可以利用一个或多个语言模型来决定何时以及如何在状态之间转换，并使用外部工具来完成模型本身难以或不可能完成的任何数量的复杂任务

2. **编排层是智能体运作的核心**
   - 一种认知架构，构建推理、规划、决策并指导其行动
   - 各种推理技术，如ReAct、思维链和思维树，为编排层提供了一个框架，用于接收信息、执行内部推理并生成明智的决策或响应

3. **工具是通往外部世界的钥匙**
   - 扩展、函数和数据存储等工具充当智能体通往外部世界的钥匙
   - 扩展在智能体和外部API之间提供桥梁，实现API调用的执行和实时信息的检索
   - 函数通过劳动分工为开发人员提供更细微的控制，允许智能体生成可以在客户端执行的函数参数
   - 数据存储为智能体提供对结构化或非结构化数据的访问，实现数据驱动的应用程序

### 未来展望

智能体的未来充满令人兴奋的进步，我们才刚刚开始触及可能性的表面。随着工具变得更加复杂，推理能力得到增强，智能体将被赋予解决日益复杂问题的能力。

此外，**"智能体链接"** 的战略方法将继续获得动力。通过结合专门的智能体——每个智能体在特定领域或任务中表现出色——我们可以创建一种"混合智能体专家"方法，能够在各个行业和问题领域提供卓越的结果。

### 重要提醒

重要的是要记住，构建复杂的智能体架构需要迭代方法。实验和完善是找到特定业务案例和组织需求解决方案的关键。

由于支撑其架构的基础模型的生成性质，没有两个智能体是完全相同的。然而，通过利用这些基础组件的各自优势，我们可以创建有影响力的应用程序，扩展语言模型的能力并推动真实世界的价值。

---

## 参考文献

1. Shafran, I., Cao, Y. et al., 2022, 'ReAct: Synergizing Reasoning and Acting in Language Models'. 可访问: https://arxiv.org/abs/2210.03629

2. Wei, J., Wang, X. et al., 2023, 'Chain-of-Thought Prompting Elicits Reasoning in Large Language Models'. 可访问: https://arxiv.org/pdf/2201.11903.pdf

3. Wang, X. et al., 2022, 'Self-Consistency Improves Chain of Thought Reasoning in Language Models'. 可访问: https://arxiv.org/abs/2203.11171

4. Diao, S. et al., 2023, 'Active Prompting with Chain-of-Thought for Large Language Models'. 可访问: https://arxiv.org/pdf/2302.12246.pdf

5. Zhang, H. et al., 2023, 'Multimodal Chain-of-Thought Reasoning in Language Models'. 可访问: https://arxiv.org/abs/2302.00923

6. Yao, S. et al., 2023, 'Tree of Thoughts: Deliberate Problem Solving with Large Language Models'. 可访问: https://arxiv.org/abs/2305.10601

7. Long, X., 2023, 'Large Language Model Guided Tree-of-Thought'. 可访问: https://arxiv.org/abs/2305.08291

8. Google. 'Google Gemini Application'. 可访问: http://gemini.google.com

9. Swagger. 'OpenAPI Specification'. 可访问: https://swagger.io/specification/

10. Xie, M., 2022, 'How does in-context learning work? A framework for understanding the differences from traditional supervised learning'. 可访问: https://ai.stanford.edu/blog/understanding-incontext/

11. Google Research. 'ScaNN (Scalable Nearest Neighbors)'. 可访问: https://github.com/google-research/google-research/tree/master/scann

12. LangChain. 'LangChain'. 可访问: https://python.langchain.com/v0.2/docs/introduction/

---

**文档说明：**
- 本文档是对Google发布的《Agents》白皮书的完整中文翻译
- 翻译日期：2026年2月11日
- 原文发布日期：2025年2月
- 译者保留了原文的结构、章节和技术术语的准确性
- 代码示例保持原样，注释已翻译为中文
Agents Companion（智能体指南）
作者：Antonio Gulli, Lavi Nigam, Julia Wiesinger, Vladimir Vuskovic, Irina Sigler, Ivan Nardini, Nicolas Stroppa, Sokratis Kartakis, Narek Saribekyan, Anant Nawalgaria, Alan Bount

版本：2025年2月

致谢
- 编辑与策展：Anant Nawalgaria
- 内容贡献者：Steven Johnson, Hussain Chinoy
- 设计师：Michael Lanning

目录
- 引言
- AgentOps（智能体运维）
- 智能体成功度量
- 智能体评估
  - 评估智能体能力
  - 评估轨迹与工具使用
  - 评估最终响应
  - 人类参与的评估（Human-in-the-Loop）
  - 更多关于智能体评估
- 多智能体与其评估
  - 理解多智能体架构
  - 多智能体设计模式及其业务影响
  - 智能体的重要组成
  - 多智能体系统的挑战
  - 多智能体评估
- Agentic RAG：检索增强生成的关键演进
  - Agentic RAG 及其重要性
  - 更好的搜索，更好的 RAG
- 企业中的智能体
  - 智能体的管理者
  - Google Agentspace
  - NotebookLM 企业版
  - Google Agentspace 企业版
- 从智能体到承包商（Contractor）
  - 合同（Contract）
  - 合同生命周期
  - 合同执行
  - 合同谈判
  - 合同反馈
  - 子合同（Subcontracts）
- 案例研究：汽车 AI 的多智能体架构实战
  - 专用智能体
  - 常见模式
    - 分层（Hierarchical）
    - 菱形（Diamond）
    - 点对点（Peer-to-Peer）
    - 协作（Collaborative）
    - 响应混合器（Response Mixer）
    - 自适应循环（Adaptive Loop）
  - 多智能体架构对汽车 AI 的优势
  - Agent Builder
- 总结
- 参考文献（Endnotes）

引言
生成式 AI 智能体相较传统的、独立的大语言模型（LLM），在问题求解与交互方式上实现了飞跃。按照最初《Agents》论文的定义，智能体是一类为达成特定目标而工程化的应用。它能够感知环境，并基于可用工具有策略地采取行动。智能体的基本原则在于将推理、逻辑与外部信息访问进行综合，从而执行任务、做出超越底层模型固有能力的决策。这些智能体具备自主运行的能力，能够独立追求目标，主动确定后续行动，往往无需明确的逐步指令。
AI 的未来是智能体化（Agentic）。

智能体的架构由三大关键元素构成，共同驱动其行为与决策：
- 模型（Model）：在智能体框架中，“模型”指充当核心决策单元的语言模型（LM），通过指令驱动的推理与逻辑框架来运行。根据智能体需求，模型可以是通用、跨模态或经微调的。
- 工具（Tools）：工具是连接智能体内部能力与外部世界的桥梁，使其能够与外部数据与服务交互。这些工具赋能智能体获取并处理现实世界信息。工具包括扩展、函数与数据存储。扩展用于打通 API 与智能体的鸿沟，使智能体可无缝执行 API；函数是完成具体任务的自包含代码模块；数据存储为模型提供对动态、最新信息的访问，确保响应具备事实性与相关性。
- 编排层（Orchestration layer）：编排层是一个循环过程，决定智能体如何同化信息、进行内部推理，并据此推动后续行动或决策。它负责维护记忆、状态、推理与规划；采用提示工程框架引导推理与规划，以便更高效地与环境互动并完成任务；可在此层应用诸如 ReAct、Chain-of-Thought（CoT，思维链）与 Tree-of-Thoughts（ToT，思维树）等推理技术。

基于上述基础概念，本伴随论文面向开发者，充当进阶主题的“102 指南”。我们将深入探讨智能体评估方法论，以及如何实践使用 Google 智能体产品来增强智能体能力，以解决复杂的真实世界问题。在讨论这些理论概念的同时，我们还将重点考察其在现实中的落地实现，尤其以汽车 AI 为一个引人注目的案例研究。汽车领域充分展现了多智能体架构在生产环境中的挑战与机遇：现代车辆需要在有网与离线条件下都能正常工作的对话式界面；在设备端与云端处理之间取得安全与用户体验的平衡；并在导航、媒体控制、消息与车载系统等专项能力间实现无缝协调。通过汽车这一视角，我们可以看到不同的协调模式——分层、协作与点对点——如何在约束显著的环境下组合成稳健、灵敏的用户体验。该案例展示了多智能体系统的实际应用，便于不同行业的企业据此进行域内适配。

任何构建过生成式 AI 的人都很快会意识到：从创意到概念验证（POC）很容易，但要确保高质量结果并推进到生产则要困难得多——智能体也不例外。质量与可靠性是上生产最常被提及的关注点，“AgentOps（智能体运维）”过程正是优化智能体构建的解决方案。

AgentOps（智能体运维）
过去两年，生成式 AI（GenAI）领域发生了重大变化，企业客户的焦点转向如何将相关解决方案落地运营化。这催生了诸多术语来描述 GenAI 的运营化，如面向 GenAI 的 MLOps、LLMOps、FMOps 与 GenAIOps。
AgentOps（智能体与运维）是 GenAIOps 的一个子类，专注于高效地将智能体运营化。它的主要新增组件包括：内部与外部工具管理、智能体大脑提示（目标、画像、指令）与编排、记忆管理以及任务分解。

每一种 “Ops” 都需要具备版本控制、通过 CI/CD 的自动化部署、测试、日志、安全，以及（尤为关键的）度量指标。这些系统通常基于指标进行某种形式的优化——即衡量系统做了什么与没做什么，衡量产出与业务指标，并将流程自动化，以获取更全面的指标，然后循序渐进地改进。这种实践可以被称为“A/B 实验”“ML 运维”或“度量驱动开发”，但它们本质上源自同样的通用方法，我们在 AgentOps 中也遵循这些原则。
请记住，新实践不会替代旧实践。DevOps 与 MLOps 的最佳实践在 AgentOps 中仍然必要，因为它们是依赖项。例如，智能体的工具使用（基于编排来调用 API）通常会使用与非智能体软件相同的 API。认证与密钥管理、安全、隐私、异常处理、节流（throttling）、配额与可扩展性仍属关键，既需要仔细的 API 设计，也需要智能体设计。

术语区分：
- DevOps（开发与运维）：通过整合人员、流程与技术，高效地将确定性软件应用推向生产。DevOps 是后续所有术语的基础。
- MLOps（机器学习运维）：在 DevOps 能力之上，专注于高效地将机器学习模型推向生产。主要区别在于 ML 模型的输出是非确定性的，且高度依赖输入数据（“垃圾进，垃圾出”）。
- FMOps（基座/基础模型运维）：在 MLOps 能力之上，专注于高效地将预训练（从零训练）或定制化（微调）的基础模型推向生产。
- PromptOps（提示与运维）：GenAIOps 的子类，聚焦提示的高效运营化。其主要的附加能力包括：提示存储、谱系、元数据管理（含评估分数）、集中式提示模板注册表，以及提示优化器。
- RAGOps（RAG 与运维）：GenAIOps 的子类，聚焦高效运营化 RAG 解决方案。其主要的附加能力包括：检索过程的离线数据准备（清洗、切片、向量化、相似度搜索与重排序）以及生成过程的提示增强与扎根（grounding）。
- AgentOps（智能体与运维）：GenAIOps 的子类，聚焦智能体的高效运营化。其主要的附加组件包括：内部与外部工具管理、智能体大脑提示（目标、画像、指令）与编排、记忆，以及任务分解。

以上各类 “Ops” 本质上都是人员、流程与技术的和谐融合，共同将机器学习解决方案高效部署到在线生产环境。必须认识到，Ops 不只是技术本身；它不是简单地构建与交付一个 ML 流水线。成功的 Ops 落地需要更深入的考虑：客户的运营模式、现有业务单元以及组织结构。唯有这种全局视角，才能确保技术真正贴合其具体需求，无缝整合进业务并最大化价值。

我们将在下一章详细阐述智能体评估，这是 AgentOps 与自动化中用于捕获有用度量的关键部分。先做一个思想实验：设想你为新智能体在生产中设置一个 A/B 实验，实验组使用新智能体，对照组不使用。在这种情境中，你衡量哪些指标以判断实验组表现更好？你衡量哪些指标来确定项目的 ROI？是某个目标被完成，还是销售总额，或是一组用户旅程中的关键步骤？这些指标必须被明确、埋点并易于分析，同时也要结合更细化的智能体评估指标。

智能体成功度量
度量指标对于构建、监控与比较智能体版本至关重要。业务指标（如收入或用户参与度）或许超出智能体本身的范畴，但它们应成为你的智能体的“北极星指标”。
大多数智能体都围绕完成目标而设计，因此目标完成率是关键的跟踪指标。同样地，一个目标可被分解为若干关键任务或关键交互；每个关键任务与交互都应独立埋点与度量。
在深入智能体细节之前，我们已识别出若干指标，且应能轻松地在仪表盘上进行跟踪。每个业务指标、目标或关键交互都将以常见的方式聚合：尝试次数、成功次数、成功率等。此外，任何应用的遥测系统都能提供的重要指标（如延迟、错误率等）对智能体也很重要。

这些指标并非智能体特有，你可用于任何软件，但对智能体构建者而言尤为重要。确定性代码只会严格执行你的指令，而智能体能做得更多，它们依赖在海量数据上训练的 LLM。对这些高层指标进行埋点，是可观测性的关键组成；你可以将它们视为智能体的关键绩效指标（KPI），用于在聚合层面提供可观测性，即对智能体的高阶视角。
用户反馈也是最重要的指标之一。即便是一个简单的点赞/点踩，或是在智能体或任务的上下文中加入用户反馈表单，也能极大帮助理解智能体的优势与需要改进的领域。这份反馈既可以来自消费级系统的终端用户，也可以来自员工、QA 测试人员、流程或领域专家对智能体的审查。
更细致的可观测性对智能体构建同样重要：能够看到并理解智能体在做什么以及为什么这么做。智能体可以通过“追踪（trace）”进行埋点，记录其内部运转的全部细节，而不仅仅是关键任务与用户交互。理论上你可以将每个内部步骤都量化为指标，但这很少见。相反，这些详细 trace 主要用于在指标或手工测试显示问题时进行调试，你可以深入细节，定位出错环节。

综上，我们一直在谈业务指标、目标、任务、人类反馈与追踪——这些都是理解你的智能体在生产中的行为与影响的方式。在开发智能体过程中，除了手动测试之外，从长期来看，自动化测试能更高效地工作，并为智能体行为提供更深入的洞察。

智能体评估
要从概念验证迈向生产就绪的 AI 智能体，一个健壮且自动化的评估框架至关重要。与评估生成模型不同，后者主要关注最终输出，智能体评估要求更深入地理解其决策过程。智能体评估可分为三个组成部分：
1) 评估智能体能力：评估智能体的核心能力，如理解指令与进行逻辑推理的能力。
2) 评估轨迹与工具使用：分析智能体为达成解法所采取的步骤，包括工具的选择、策略以及方法的效率。
3) 评估最终响应：评估智能体最终输出的质量、相关性与正确性。

评估智能体能力
在评估具体的智能体用例之前，公共基准与技术报告可以为“核心能力与局限性”提供洞见，从而在构建智能体用例时有所考虑。公共基准覆盖大多数基础智能体能力，如模型表现、幻觉、工具调用与规划。例如，工具调用（选择并使用合适工具的能力）可用 Berkeley Function-Calling Leaderboard（BFCL）与 τ-bench 展示，同时也总结了常见错误。另一个例子，PlanBench 旨在跨多个领域与具体能力评估规划与推理。
但工具调用与规划并非唯一需要考虑的能力。智能体会从其 LLM 与其他组件继承行为。同样地，智能体与用户的交互在传统的对话式设计系统与工作流系统中已有历史，因此也可继承用于衡量这些系统有效性的指标与度量。

全面的智能体基准（如 AgentBench）试图在多个场景中捕捉端到端表现。当场景与智能体用例相符时，这更贴近现实；但若其评估的是你的智能体并未实现的能力，则参考价值有限。要以既具体又通用的方式模拟环境、工具、指令与用例要求非常困难。公司与组织也在为专项用例设立公共基准，如 Adyen 的数据分析排行榜 DABStep；如果你理解评估方法与排行榜上的智能体，它可能更具针对性。
公共基准是很好的起点，有助于了解可能性与识别需要警惕的坑。大多数基准评估都包含对常见失败模式的讨论，可指导你搭建适用于自身用例的评估框架。

在公共评估之外，你需要在各种场景下评估智能体的行为，确保其按你的期望工作。你将模拟与智能体的交互并评估其响应。这既包括最终响应的评估，也包括沿途采取的一系列步骤（轨迹）。这二者是我们建议的两种最常用、最实用的评估方式。除此之外，你还可以使用许多其他评估技术，用于更细的子组件或更广泛的方式。
软件工程师会将其类比为代码的自动化测试。对自动化测试的投入能为你节省时间，并增强对软件构建的信心。对智能体而言，这种自动化更快带来回报，无论在时间还是信心方面。精心策划评估数据集，对于准确代表智能体将遇到的用例尤为重要，这一点甚至比软件测试更为重要。

评估轨迹与工具使用
智能体通常在响应用户之前会执行若干动作。它可能将当前输入与会话历史比较以消歧术语，或查阅政策文档，搜索知识库，或调用 API 以保存工单。每一个动作都是路径（也称“轨迹”）上的一步。每次智能体做事，底层就存在一条动作轨迹。
比较“期望的轨迹”与“智能体实际采取的轨迹”，对于希望调试应用的开发者来说尤其有用，可识别错误或低效之处，并最终提升性能。

常见的基于“参考真值（ground-truth）”的自动化轨迹评估（六类）：
1) 精确匹配（Exact match）：要求智能体产出的动作序列（“轨迹”）与理想解法完全一致。这是最严格的指标，不允许偏离。
2) 顺序匹配（In-order match）：评估智能体完成期望轨迹的能力，同时接受额外动作但不予惩罚。只要按照顺序完成核心步骤即可。
3) 任意顺序匹配（Any-order match）：与顺序匹配相比，该指标忽略顺序。只要智能体包含所有必要动作即可，同时允许额外步骤。
4) 精确率（Precision）：预测轨迹中的工具调用，有多少是参考轨迹所认为的相关或正确的？
5) 召回率（Recall）：参考轨迹中的必要工具调用，有多少被预测轨迹捕获？
6) 单工具使用（Single-tool use）：判断轨迹中是否包含某个特定动作。用于理解智能体是否“已经学会”使用某一工具。

将这些指标视作分析与调试智能体轨迹的不同视角。各指标各有优劣，且并非所有场景都适用。例如，有些用例要求严格遵循理想轨迹，而另一些用例则允许更具创造性的偏离。一个明确的局限是：此评估需要已有参考轨迹。尽管此类基于参考真值的自动化轨迹评估在常用库中很普遍，研究也在推进更高效的“智能体自评”方法，如 2024 年的“Agent as a Judge（智能体为裁判）”。

评估最终响应
最终响应评估归结为一个简单问题：你的智能体是否达成其目标？你可以根据具体需求定义定制化的成功标准。例如，评估一个零售客服机器人是否准确回答产品问题；或评估一个研究智能体是否有效地以合适的语气与风格总结发现。要自动化这一过程，你可以使用“自动评审器（autorater）”——充当裁判的 LLM。给定输入提示与生成的响应，autorater 会模拟人工评估，根据你提供的评估标准进行打分。由于缺少参考真值，这一评估的关键在于你需非常精确地定义评估标准，这是你的评估所关注的核心。各类库中有许多预定义标准，可作为起点并进行微调，以贴合你对“好”的定义。

人类参与的评估（Human-in-the-Loop）
智能体开发与评估领域在快速演进。评估 AI 智能体面临重大挑战，包括明确目标、设计逼真的环境、处理随机性行为，以及确保公平与缓解偏见（尤其在社会影响场景中）。因此，除了此前讨论的自动化评估（预定义指标与自动评审器）之外，必须引入人类参与（Human-in-the-Loop）。这对需要主观判断或创造性问题解决的任务尤其有价值，也可用于校准与复核你的自动化评估方法是否有效且符合偏好。关键益处包括：
- 主观性：人类可评估难以量化的品质，如创造力、常识与细微差异。
- 语境理解：人类评估者能考虑智能体行动的更广泛语境及其影响。
- 迭代改进：人类反馈为优化智能体行为与学习过程提供宝贵洞见。
- 评估评估者：人类反馈也可用于校准与优化你的自动评审器。

落地人类参与评估的方法：
- 直接评估：人类专家对智能体在具体任务上的表现进行直接评分或打分。
- 比较评估：专家将智能体的表现与其他智能体或你的先前版本进行对比。
- 用户研究：参与者与智能体交互，并就其行为、可用性与总体有效性提供反馈。

更多关于智能体评估
本节从实践视角讨论智能体评估，但这只是冰山一角。智能体评估面临诸多挑战：评估数据可能难以获取；尽管可使用合成数据或判官型 LLM（LLM-as-a-Judge），评估仍可能不完整；同时，LLM-as-a-Judge 的度量可能过度关注最终结果，而忽略智能体的推理与中间动作，错失关键洞察。此外，智能体系统的评估方法在对话系统与工作流系统中已积累历史，我们需要探索如何继承这些方法与指标来评估智能体的能力，如在多次交互中提升任务绩效的能力。多模态生成的评估更为复杂：图像、音频与视频的评估需要各自的方法与指标。最后，真实世界的环境充满动态与不可预测性，使得在受控设置中评估智能体变得困难。
展望未来，为解决这些开放挑战，智能体评估领域正快速演进。关键趋势包括：向过程导向评估转型，优先理解智能体的推理；增加 AI 辅助评估方法，以提升可扩展性；更强调真实世界应用语境。新的标准化基准也在获得 traction，从而促进不同智能体之间的客观比较；同时，更加重视可解释性与可理解性，以提供更深的智能体行为洞察。
要实现智能体的负责、有效与伦理部署，唯有持续改进评估方法。

自动化评估方法的优劣比较（简述）
- 人类评估：优势在于捕捉细微行为、考虑人类因素；劣势在于主观、耗时、昂贵、难以扩展。
- LLM 作为裁判（LLM-as-a-Judge）：优势在于可扩展、高效、一致；劣势可能忽视中间步骤，受限于 LLM 能力。
- 自动化指标：优势在于客观、可扩展、高效；劣势在于可能无法覆盖全部能力，易被“游戏化”。

多智能体与其评估
随着 AI 系统显著演进，正转向多智能体架构，即多个专用智能体协作实现复杂目标。多智能体系统类似一个专家团队：每位专家在某一领域专精，协同解决复杂问题。每个智能体都是独立实体，可能使用不同的 LLM，具备各自独特角色与上下文；智能体相互通信与协作以达成共同目标。这与传统的单智能体系统不同：后者由一个 LLM 处理任务的所有方面。

多智能体系统相较单智能体系统的优势：
- 提升准确性：智能体间可互相交叉检查，从而得到更准确的结果。
- 改善效率：智能体可并行工作，加快完成任务。
- 更好地处理复杂任务：将大任务拆解为可管理的子任务，每个智能体聚焦某一方面。
- 增强可扩展性：通过添加具备专长的新智能体，系统可轻松扩展。
- 改善容错性：若一个智能体失败，其他智能体可接管其职责。
- 降低幻觉与偏见：融合多个智能体的视角，可降低幻觉与偏见，提升输出的可靠性与可信度。

理解多智能体架构
与传统的单体式 AI 系统不同，多智能体架构将问题分解为由专用智能体处理的不同任务。每个智能体在定义角色下运行，动态与其他智能体互动，以优化决策、知识检索与执行。这类架构实现更结构化的推理、分布式问题求解与可扩展的任务自动化，相较单智能体工作流有范式上的转变。
核心上，多智能体系统利用模块化、协作与层级原则构建稳健的 AI 生态。可按功能对智能体分类，例如：
- 规划者（Planner Agents）：负责将高层目标分解为结构化子任务。
- 检索者（Retriever Agents）：动态抓取相关外部数据，优化知识获取。
- 执行者（Execution Agents）：执行计算、生成响应或与 API 交互。
- 评估者（Evaluator Agents）：监控与验证响应，确保一致性与符合目标。

通过这些组件，多智能体架构超越简单的提示式交互，实现具有适应性、可解释与高效的 AI 驱动工作流。

多智能体设计模式及其业务影响
为了设计有效的多智能体架构，涌现出一系列设计模式。这些模式定义了交互协议、委派机制与角色分配，使企业能以结构化方式部署 AI 驱动自动化。常见模式包括：
- 顺序（Sequential）：智能体按顺序工作，每个智能体完成其任务后将输出传给下一个智能体。类比装配线。
- 分层（Hierarchical）：智能体以层级结构组织，由“管理者”智能体协调工作流，并向“执行者/工人”智能体分派任务。领导智能体做战略决策，跟随智能体据此执行。
- 协作（Collaborative）：智能体协同工作，共享信息与资源以达成共同目标。类比协作研究团队。
- 竞争（Competitive）：智能体相互竞争以获得最佳结果。类例如 Overcooked-AI 等游戏中，LLM 充当玩家，需要协调行动以实现共享目标，同时竞争资源并优化个体表现。

企业可通过这些模式降低运营瓶颈、改善知识检索与增强自动化的可靠性。多智能体系统使公司能在确保决策与工作流执行的敏捷性前提下扩大 AI 部署规模。

智能体的重要组成
基于 LLM 的 AI 智能体架构由若干互相关联的组件构成，这些组件对自主运行与智能交互至关重要：
- 交互封装（Interaction Wrapper）：充当智能体与环境的接口，管理通信并适应多种输入/输出模态。
- 记忆管理（Memory Management）：包括用于即时上下文的短期工作记忆、缓存与会话，也可包含长期存储用于保存学习到的模式与经验（如情节、示例、技能或参考数据）。同时包括“反思（reflection）”，决定哪些短期信息（如用户偏好）应拷贝至长期记忆（如用户画像），以及是否可在智能体、任务或会话间共享。
- 认知功能（Cognitive Functionality）：通常由 CoT、ReAct、推理/思考或规划子系统支撑——允许智能体将复杂任务分解为逻辑步骤并进行自我纠错。在一些场景中还包含用户意图澄清（不确定时发问）。
- 工具集成（Tool Integration）：使智能体能够使用外部工具，从而拓展其能力。动态工具注册表支持发现、注册与“Tool RAG”。
- 流/路由（Flow / Routing）：管理与其他智能体的连接，支持动态邻居发现与高效通信。可实现为将任务委派给后台智能体、将用户交互移交给某个智能体，或将智能体作为工具来使用。
- 反馈回路/强化学习（Feedback Loops / RL）：通过处理交互结果并优化决策策略，实现持续学习与适应。生成式 AI 智能体很少采用传统 RL 训练，但可将历史绩效指标纳入未来决策。
- 智能体通信（Agent Communication）：多智能体系统成功的关键在于高效的智能体间通信。智能体到智能体（A2A）通信协议支持结构化高效通信，使智能体能达成共识并协作解决复杂问题。
- 远程智能体通信（Remote Agent Communication）：当系统包含远程智能体时，通信协议尤为重要。异步任务与会话需具备持久性，并在用户不在会话时通过通知更新。智能体之间的协商需支持将用户拉回会话以及当前 UX 能力。
- 智能体与工具注册表（网格/mesh）：当工具或智能体数量超过少量时，需要一个健壮系统来发现、注册、管理、选择与使用“网格”中的工具或智能体。至关重要的是对工具与智能体的本体与描述、能力与要求、以及绩效指标进行管理。你的智能体将基于该系统的数据进行规划并选择工具/智能体，选择的质量取决于系统数据质量。

这些架构要素为多智能体系统中 LLM 智能体的自主运行与协作能力提供了坚实基础。

多智能体系统的挑战
多智能体系统有诸多优势，同时也面临若干挑战：
- 任务通信：当前多数智能体框架用消息传递，而非结构化异步任务。
- 任务分配：高效地在不同智能体之间划分复杂任务存在挑战，反馈回路往往需开发者自行实现。
- 协同推理：让智能体之间有效辩论与共同推理，需要复杂的协调机制。
- 上下文管理：在智能体之间维护所有信息、任务与对话可能令人不胜其烦。
- 时间与成本：多智能体交互在计算上昂贵且耗时，导致更高的运行成本与更长的用户延迟。
- 系统复杂性：类似微服务架构，每个微服务更灵活与简单，但系统整体通常更复杂。

解决这些挑战对构建稳健高效的多智能体系统至关重要。

多智能体评估
幸运的是，多智能体系统的评估是单智能体评估的自然延伸。智能体成功度量保持不变：以业务指标为北极星，目标与关键任务成功指标，以及应用遥测指标（如延迟与错误）。为多智能体系统埋点 trace 能帮助在复杂交互中进行调试与理解系统行为。
我们在“智能体评估”一节讨论了“评估轨迹”与“评估最终响应”，作为智能体自动化评估的两种最佳途径，这对多智能体系统同样适用。多智能体系统的动作轨迹可能涉及多个智能体，甚至全部智能体。尽管多个智能体在协作，最终仍由一个最终答案返回给用户，可单独进行评估。
由于多智能体系统的步骤更多，你可以深入到每一步进行评估：既可孤立评估各智能体，也可评估系统整体。轨迹评估是一个可扩展的方法，恰好用于此目的。

多智能体系统的特有问题包括：
- 协作与协调：智能体如何协作与协调其行动以实现共同目标？
- 规划与任务分配：我们是否提出了正确的计划？是否遵循计划？子智能体是否偏离主计划或陷入死胡同？
- 智能体利用：系统是否有效地选择正确的智能体？是否恰当使用智能体作为工具、委派后台任务或转移用户交互？
- 可扩展性：随着智能体数量增加，系统质量是否提升？延迟是否降低？效率是否提高或下降？

这些问题将指导开发者识别多智能体系统的改进空间。你将用与单智能体系统相同的工具来回答这些问题，但分析复杂度会显著上升。

Agentic RAG：检索增强生成的关键演进
在多智能体架构中，一个重要的进步是 Agentic RAG（智能体化 RAG）。传统 RAG 管道采用静态方式——从向量数据库检索知识并馈送给 LLM 进行综合。然而，这种方式在处理含糊、需要多步或多视角的问题时常常乏力。
Agentic RAG 引入了自主的检索智能体，它们基于迭代推理主动优化检索过程。这些智能体在以下方面增强检索：
- 具备上下文感知的查询扩展：不再依赖单次搜索，智能体会生成多种查询改写，以检索更相关与更全面的结果。
- 多步推理：将复杂查询分解为更小的逻辑步骤，按序检索信息以构建结构化响应。
- 自适应来源选择：不仅从单一向量数据库拉取数据，检索智能体会基于上下文动态选择最佳知识来源。
- 验证与纠错：评估智能体会在整合前交叉检查检索到的知识，以发现并避免幻觉与矛盾。

这极大改善了响应的准确性、可解释性与适应性，对于法律研究、科学发现、商务智能等处理复杂知识检索任务的企业尤为关键。

Agentic RAG 及其重要性
Agentic RAG 将 RAG 的优势与智能体的自主性相结合。传统 RAG 系统从外部知识源检索相关信息以增强 LLM 响应。Agentic RAG 进一步由智能体来编排检索过程、评估检索到的信息并决定如何最佳利用它。
相较传统 RAG，Agentic RAG 的优势包括：
- 提升准确性：智能体可评估检索信息的质量并决定信任哪些来源，从而得到更准确可靠的响应。
- 增强上下文理解：智能体能综合用户查询与检索信息的语境，从而生成更相关、更有意义的响应。
- 提高适应性：智能体可适应信息需求的变化，动态调整检索策略，以提供最新且最相关的信息。这在医疗、金融、法律研究等信息快速演化的复杂领域尤为重要。

更好的搜索，更好的 RAG
几乎所有 RAG 方法都需要一个搜索引擎来索引与检索相关数据。引入智能体可对查询进行细化，并对过滤、排序与最终答案进行优化。Agentic RAG 的智能体通常会执行多次搜索以检索信息。
对于想要优化现有 RAG 实现的开发者，通常在引入智能体之前先改善搜索结果（以召回衡量）更有价值。主要技术包括：
- 解析源文档并进行切片：Vertex AI Layout Parser 能处理复杂文档版式、嵌入表格与图像（如图表），并使用语义切片保持段块主题一致，基于标题层级组织。
- 为段块添加元数据：同义词、关键词、作者、日期、标签与类别，支持搜索结果的提升/压制/过滤；这些增强为用户或智能体提供更细粒度的搜索控制。
- 微调嵌入模型或添加搜索适配器以改变嵌入空间：使向量索引更好地表示你的领域，而非使用通用嵌入模型。
- 更快的向量数据库可提升搜索质量：在嵌入搜索中，必须在速度与准确性之间权衡，升级到超快的 Vertex AI Vector Search 可同时改进延迟与质量。
- 使用排序器（ranker）：向量搜索快速但近似，应返回数十或数百结果，再由更复杂的系统进行重排序，确保前几条结果最相关或最佳。
- 实施“扎根校验（check grounding）”：在有扎根生成的场景中，确保每个短语都可由检索段块引用。

Vertex AI Search 是一个强大的搜索引擎，为你的数据提供 Google 级别的搜索，可用于任何 RAG 或 Agentic RAG 实现。上述各组件在 Vertex AI Search 中均可自动使用，无需开发时间。对于希望自行构建搜索引擎的开发者，上述每个组件都通过独立 API 暴露，且 RAG Engine 可通过类似 LlamaIndex 的 Python 接口轻松编排整个管线。

企业中的智能体
智能体的管理者（Manager of agents）
2025 年是智能体之年，尤其是在企业语境下，企业将开发与使用智能体来协助员工完成特定任务，或在后台自主执行自动化。业务分析师可以轻松揭示行业趋势，生成由 AI 洞察驱动的高质量数据演示。HR 团队可以革新员工体验，简化入职流程，甚至处理如 401k 选择等复杂任务。软件工程师能主动识别并解决缺陷，使其更高效地构建与迭代，加速发布周期。市场人员可以进行更深入的绩效分析，优化内容推荐，并轻松微调活动以获得更佳结果。
我们看到两类智能体：
1) 助手（Assistants）：与用户交互，接收任务、执行任务并返回结果的智能体。由 Gems 或 GPTs 等框架普及的对话式智能体通常属于此类。助手可以是通用的（可帮助处理多种任务），也可以专注于特定领域或任务。示例包括：帮助安排会议、分析数据、写代码、撰写营销通稿、帮助销售处理机会、或按照用户要求进行深入研究等。这些智能体可以同步快速返回信息或执行任务，也可以运行更长时间后再返回（如深入研究型智能体）。
2) 自动化智能体（Automation agents）：在后台运行，监听事件，监控系统或数据的变化，并进行智能决策与行动。行动可包括：对后端系统执行操作、进行验证测试、修复问题、通知相关员工等。这些将成为未来自动化的骨干。从前我们需要编写专门代码来明确自动化逻辑，现在我们可以依赖智能体的通用决策能力。
随着时间推移，知识工作者将越来越多地成为智能体的“管理者”。他们会将任务分配给多个智能体并进行管理，检查是否有智能体需要帮助或需要审批才能继续；使用某个智能体的输出发起新任务；监控长时任务的执行，以便审查与“纠偏”。新的用户界面将涌现，以支持这类虚拟团队管理，包括编排、监控与管理一个多智能体系统，智能体执行任务、调用（甚至创建）其他智能体。
Google Agentspace 致力于提供这类体验，支持：
- 使用零/低代码界面或完整代码框架创建新智能体，以实现专用助手与自动化智能体；
- 为公司管理员配置与管理智能体的访问；
- 在合适的时候调用正确的智能体；
- 在适用于团队管理的 UI 中监控、管理与编排多个智能体。

Google Agentspace
Google Agentspace 提供一套由 AI 驱动的工具，旨在提升企业生产力：便捷访问相关信息并自动化复杂的智能体化工作流。它融合了 Gemini 的高级推理能力、Google 搜索基础设施的力量，以及对企业数据（无论其存储位置如何）的安全访问。
Agentspace 直击传统知识管理系统的局限，这些系统在个性化、自动化答案生成、上下文理解与信息检索的全面性方面往往不足。它通过整合分散的内容源、生成扎根且个性化的响应、并简化运营工作流，赋能员工高效访问信息。关键能力包括：摄取多种数据格式、与 SaaS 平台数据同步、提供基于访问控制的搜索结果与 AI 生成答案、并将 AI 助手与智能体融入统一工作流。
Agentspace 企业版架构建立于若干核心原则之上：
- 内置信任：强调安全、可解释性与治理，支持 SSO 认证、集成权限模型与用户级访问控制。
- Google 智能：通过机器学习洞察用户行为与内容模式，利用语义理解、知识图谱与 LLM 提供高度相关的结果。
- 全域连接：连接多样的企业系统，支持按需与自动数据刷新，消除信息孤岛。
- 企业级定制与用户级个性化：对搜索功能、推荐、LLM 与知识图谱提供细粒度控制，依据用户角色、权限与检索历史提供定制体验。
- 实时反馈与自适应：通过机器学习与用户输入持续优化结果。
- 混合 RAG：支持定制化数据融合，使基于企业数据的生成式 AI 应用具备扎根性。
- 可扩展性：面向地区、语言与峰值需求的扩展进行工程化设计。

安全始终是重中之重。Agentspace 构建于 Google Cloud 的“以安全为设计”的基础设施之上，提供细粒度的 IT 控制（RBAC、VPC Service Controls、IAM 集成），确保数据安全与合规，支持企业放心部署 AI 智能体。

NotebookLM 企业版
NotebookLM 是一款研究与学习工具，旨在简化理解与综合复杂信息的过程。用户可以上传多种来源材料（文档、笔记等），并利用 AI 的力量加深理解。可以将其视为一个专属研究助理：加速研究过程，让用户从“信息收集”迈向“真正理解”。
NotebookLM Plus 在此基础上提供高级功能，如更大的来源存储、更复杂的 AI 分析工具（更细粒度的摘要选项、增强的问答能力、或更有效地识别不同来源间的关联）。
NotebookLM Enterprise 将这些能力带入企业环境，简化员工与企业数据的交互与洞察提取。它不仅支持上传与综合信息，还帮助发现隐藏模式并以创新方式与数据交互。一个典型例子是 AI 生成的音频总结功能，支持“听”研究内容以增强理解与吸收效率。技术上，它采用 LLM 处理上传文档、抽取关键概念并生成摘要；音频总结功能采用具备高级韵律控制的 TTS 技术，确保清晰与自然；企业版整合企业级安全与隐私特性以妥善处理敏感公司数据。

Google Agentspace 企业版
Agentspace 为员工提供一个统一的、企业品牌化的、多模态搜索智能体，作为企业信息的权威来源。基于 Google 的强大搜索能力，Agentspace 提供卓越的对话式辅助。员工可以得到复杂问题的答案、主动推荐，以及对任何来源信息的统一访问，覆盖非结构化数据（如文档、电子邮件）与结构化数据（如表格）。内置翻译能力确保对不同语言信息的全面理解。面向常见第三方应用（如 Confluence、Google Drive、Jira、Microsoft SharePoint、ServiceNow 等）的预构建连接器，帮助员工无缝访问与查询相关数据源，支持更明智的决策。
Agentspace Enterprise Plus 支持创建面向特定业务职能的定制 AI 智能体。该平台使开发与部署具备上下文感知的生成式 AI 智能体成为可能，赋能各部门（营销、财务、法律、工程等）的员工进行更有效的研究、快速生成内容与自动化重复任务（包括多步工作流）。集中式界面简化这些专用智能体的发现与访问，推动 AI 的规模化采用。定制智能体将连接内外部系统与数据，贴合公司领域与策略，甚至可能使用基于专有业务数据训练的机器学习模型。平台提供面向构建者的智能体开发、部署与生命周期管理工具。

从智能体到承包商（Contractor）
如今在各类工具与平台中定义 AI 智能体的接口通常非常简单，通常包括：指定目标、文本指令、可用工具与一组示例。尽管这足以原型化演示，但可能导致定义欠明确，这也是智能体从原型走向生产困难的原因之一。
我们建议演进智能体接口，将其发展为“遵循合同的智能体（Contract-adhering agents）”，以解决复杂任务，尤其是在“风险较高的情境”中。

合同（Contracts）
核心思想是：在任务请求方与智能体（承包商）之间明确并标准化合同，从而：
1) 尽可能精确地定义预期的成果，类似现实世界中我们与受托公司签订服务合同时所做的。这使智能体（承包商）能根据期望进行验证，并迭代直至达成目标。
2) 允许对任务进行谈判、澄清与细化，避免定义中的歧义，填补对目标的共识缺口。
3) 定义承包商生成“子合同（Subcontracts）”的规则，以标准方式分解复杂任务为更小任务。

示例：合同数据模型（字段/描述/是否必填）
- 任务/项目描述（是）：详细描述承包商需完成的内容，越具体越无歧义越好。
- 交付物与规格（是）：精确描述期望成果与交付物，包括满足期望的规格列表，以及如何验证交付物符合期望的细节。
- 范围（否）：明确承包商负责完成的任务范围，并细分每个方面，同时明确不在范围内的内容。
- 预期成本（是）：给出完成任务的成本预期，通常是任务复杂度与所用工具的函数。
- 预期周期（是）：给出完成任务的时间预期。
- 输入来源（否）：指定可使用且对完成任务有用的输入数据来源。
- 报告与反馈（是）：规定反馈回路的形式：更新频率、反馈的机制/界面（邮件、API 等）。

示例：合同迭代（反馈与谈判）数据模型（字段/描述/是否必填）
- 定义不充分（否）：指出任务中需要澄清的欠明确之处。
- 成本谈判（否）：认为完成任务的成本过高。
- 风险（否）：提示履行合同的潜在风险。
- 需要额外输入（否）：表达为履行合同所需的额外数据或信息类型。

合同生命周期
- 生命周期包括：合同定义、谈判与执行。执行引擎应能遵照合同规范完成任务。
- 在合同执行中，优先质量与完整性，而非延迟，以充分利用 LLM 的能力，例如生成不同解法、进行评审/打分/演化，迭代与自我验证直到满足预定义的验证器。
- 能够依据客观标准验证解法的能力在 AI 领域中极为有效，诸如 AlphaCode 等成功系统便是典型。

合同谈判
针对自动化智能体，合同的一个核心假设是：很多企业任务在“延迟与成本约束较少”的条件下，能显著受益于 LLM 的强大能力。能够处理更复杂的任务，并使客户得以信赖承包商的结果，将确保真正的企业价值。当然，我们仍需要“相对优先级”的概念，确保任务被适当排序、资源被公平分配。因此我们引入“成本”这一概念（通常相对于客户或合同发起方），双方可就成本进行讨论与谈判，以确保在合同发起方的其他合同之间，当前合同获得相称资源。承包商还可就合同的其他方面谈判，例如规格与交付物（也参见反馈部分）。

合同反馈
合同为提供反馈与解决歧义提供载体。随着任务复杂度提升，尽早提出歧义或与任务规格相关的其他问题至关重要。承包商可在收到合同后立即给出“初始合同评估”的反馈，并按照合同预定义的频率给出后续反馈。反馈既包含澄清请求，也可指出任务定义不充分或错误（不一致、规格冲突、澄清等）。

子合同（Subcontracts）
尽管不直接属于合同定义与规范的一部分，但“将任务分解为子任务并生成子合同”的能力是驱动承包商引擎的核心概念。当任务被认为过于复杂而无法直接处理时，承包商可将其分解为更小的易解子任务，并将其加入执行队列。之所以能实现，是因为我们对合同进行了形式化，使承包商能以统一且标准化的方式生成、处理与操作其他合同。

案例研究：Google 的 AI 共科学家（Co-Scientist）
Google 的 AI 共科学家是一个多智能体 LLM 系统在科学研究中的典型应用。系统由一组具备各自角色与专长的智能体组成，以协作加速科学发现的进程。这些智能体协同生成、评估与改进假设，模拟科学探究的迭代过程。
共科学家系统采用“生成、辩论与演化”的方法，源自科学方法论：生成多样化假设、批判性评估其潜力、并通过持续反馈与分析进行改进。系统利用不同 LLM 的特长（每个在研究流程中的不同方面专精），从而获得更全面与稳健的结果。
例如，在肝纤维化治疗的研究中，共科学家不仅识别了现有药物，还提出了新的机制与有前景的候选药物，展现其产生新洞见的潜力。主要组件包括：
- 数据处理智能体：聚合与结构化大量实验数据。
- 假设生成器：基于现有研究与新发现提出潜在解释。
- 验证智能体：运行模拟并在给研究者之前对结果进行验证。
- 协作智能体：在不同研究团队之间传达发现，促进跨学科合作。

汽车 AI：多智能体架构的实战应用
为展示多智能体概念如何在实践中落地，以下说明一个面向车载对话式 AI 的综合多智能体系统：多个专用智能体协作，提供直观无缝的车内体验。
我们先看专用智能体的实例，然后是组合这些智能体形成多智能体系统的常见模式。

专用智能体示例
- 对话式导航智能体（Conversational Navigation Agent）
  - 专注于帮助用户寻找地点、给出建议并进行导航，调用 Google Places 与 Maps 等 API。理解导航意图，如“附近哪里有寿司店”，查询 Places API 获得结果，依据用户偏好与历史数据重排序，并向车载系统发送导航指令。
  - 示例交互：
    用户：“我想停下来吃午饭。在去慕尼黑的路线上，有哪些不错的餐馆？”
    导航智能体：“我在你 A9 路线沿途找到了三家评分不错的餐馆。再过 25 公里，在英戈尔施塔特出口有一家‘Gasthaus Alte Mühle’，评分 4.5 分——评论称赞它的巴伐利亚传统菜和露天啤酒花园。再过 45 公里，服务区里的‘La Strada’评分 4.1 分，适合快速的意式简餐。如果你还能再等 70 公里，阿勒斯豪森附近的‘Zeitlos’评分 4.7 分——稍微更精致，主打从农场到餐桌的菜式。你对哪一家更感兴趣？”
    用户：“那家巴伐利亚风味的听起来不错。那里停车方便吗？离高速多远？”
    导航智能体：“Gasthaus Alte Mühle 有大约 40 个车位的专用停车区，距离 A9 英戈尔施塔特北（Ingolstadt-Nord）出口仅 1.2 公里——开车约 2 分钟即可到达。他们以烤猪肉（Schweinebraten）和自制土豆团子闻名。中午人会比较多，不过目前显示为中等拥挤。要不要将它设为你的目的地并为你导航？如果现在出发，大约 12:15 能到。”

- 对话式媒体检索智能体（Conversational Media Search Agent）
  - 专注于帮助用户搜索与播放音乐、有声书与播客。从本地数据库或流媒体服务检索媒体，必要时使用网页搜索补充；根据情境（心情、天气、时间）建议媒体；处理语音命令，如“播放适合长途驾驶的动感音乐”；识别相似艺术家。
  - 示例交互：
    用户：“我这段高速路程很长，放点有节奏的音乐帮我提神。”
    对话式媒体检索智能体：“我将为你播放一份动感驾驶歌单，帮助保持精力。先从 Queen 的 ‘Don't Stop Me Now’ 开始，接着是一些 Daft Punk 和 Stromae 的曲目。我还加入了几首符合你偏好的热门欧洲电台歌曲。我已将音量调整到适合道路环境的水平。如果想跳过，请说‘下一首’。”

- 信息撰写智能体（Message Composition Agent）
  - 专注于帮助用户在驾驶时起草、总结与发送消息或邮件。解析“告诉 Alex 我会晚到”等语音命令；使用自然语言模型撰写上下文适当的消息；提供草稿预览与用户修改选项；整合 SMS、WhatsApp、电子邮件等。
  - 示例交互：
    用户：“E40 上车流很大。帮我告诉团队，我参加早会会晚 20 分钟。”
    信息撰写智能体：“我已为你的工作团队准备好一条消息：‘E40 堵车。我参加早会大约会晚 20 分钟。请先开始。’需要我发送到你的‘工作团队’群聊吗，还是你想先修改一下？”

- 车主手册智能体（Car Manual Agent）
  - 借助 RAG 系统回答车辆相关问题。检索与用户问题相关的车主手册片段；用 LLM 总结与上下文化；必要时链接至详细文档或教学视频。
  - 示例交互：
    用户：“在这辆大众车里，如何关闭车道保持辅助？”
    车主手册智能体：“要关闭大众的车道保持辅助，请按方向盘左侧带‘车辆与车道’图标的按钮。关闭后，你会在仪表显示中看到确认提示。你也可以在信息娱乐系统里永久关闭：依次进入‘设置 > 驾驶辅助 > 车道保持’。需要我带你在设置菜单中一步步操作吗？”

- 通用知识智能体（General Knowledge Agent）
  - 专注回答世界、历史、科学、文化等事实性问题。访问广泛知识库，保持事实扎根、避免幻觉；保持上下文意识回答后续问题。
  - 示例交互：
    用户：“说一个关于萨尔茨堡的有趣事实。”
    通用知识智能体：“奥地利的萨尔茨堡是历史上最著名的作曲家之一莫扎特的出生地。除了这一众所周知的事实之外，萨尔茨堡老城是联合国教科文组织的世界文化遗产，《音乐之声》的部分场景于 1964 年在此拍摄。自 1920 年以来，这里每年都会举办萨尔茨堡艺术节，它是世界上最负盛名的音乐与戏剧节之一。”

常见模式
- 分层模式（Hierarchical Pattern）
  - 一个中心“编排智能体”负责分类查询并路由到专用智能体。例如“附近寿司店”路由到导航智能体；“晚间目的地天气”路由到天气信息智能体。编排智能体分析域与意图、保持多轮对话上下文与回退策略。
  - 示例交互：
    第一轮：
    用户：“前面有没有卫生间干净的服务区？”
    编排智能体：[内部路由至导航智能体]
    导航智能体：“前方 20 公里，在 E19 上有一个服务区 Aire de Waremme。它在去年翻新，设施和清洁度评分都很好。那里还有一家 Paul 面包店和一家快餐餐厅。”
    第二轮：
    用户：“今晚到达目的地会下雨吗？”
    编排智能体：[识别为天气查询并路由至天气信息智能体]
    天气信息智能体：“你的目的地布鲁塞尔今晚有 60% 概率出现小雨，大约从 19:00 开始。气温在 14°C 左右。如果你计划在户外活动，建议带一把雨伞。”

- 菱形模式（Diamond Pattern）
  - 分层模式的变体：专用智能体的响应在返还用户前统一通过一个“调谐/复述智能体”进行风格、语气与呈现方式的调整（如驾驶场景的信息密度与紧迫性）。例如导航或车主手册输出先经过 Rephraser Agent，再进行 TTS。
  - 示例交互：
    [车主手册智能体的“原始响应”（复述前）]：“当轮胎压力监测系统报警时，车辆检测到一个或多个轮胎的充气压力已低于建议值（2.2 bar）。受影响轮胎的压力约为 1.8 bar，比建议值低约 18.75%。这并不构成立即的安全隐患，但长时间在胎压不足的情况下行驶会导致燃油效率下降、轮胎寿命缩短，并可能影响车辆操控特性。建议尽快前往服务站，将胎压充至规定值。”
    复述智能体（Rephraser Agent）：[根据驾驶情境调整信息密度与紧迫性]
    最终回复给用户：“你的右前轮胎压有点低——降到了 1.8 bar。继续开是安全的，但建议在下一个加油站补充气压。胎压过低会影响油耗并加速轮胎磨损。如果需要，我可以帮你查找附近可以补气的地点。”
  - 示例变换：
    初始响应（客观中性）：“我发现附近有一家评分很高的寿司餐厅，名为 Sakura Sushi，地址是 Main 街 123 号。评分 4.7 分，营业至晚 10 点。需要我开始导航吗？”
    复述后（活泼风格）：“想吃寿司？没问题！去 Main 街 123 号的 Sakura Sushi，鲜鱼现切、酱油畅快！评分 4.7 分，营业到晚 10 点。准备开启一场鲜味之旅？”

- 点对点（Peer-to-Peer）
  - 当智能体识别到编排路由出错时，智能体间可相互移交查询，从而提升系统的鲁棒性与纠错能力。
  - 优势包括：对错误路由的韧性；路由的领域专家性；降低中心编排逻辑复杂度。
  - 示例场景：
    1) 用户提出：“在附近找一家吃寿司的地方”
    2) 编排智能体正确地将请求路由到对话式导航智能体，后者提供附近寿司餐厅的信息。
    3) 用户追问：“纽约中央公园有多大？”
    4) 编排智能体可能会因为上一轮语境仍是“导航”，而再次将请求路由给对话式导航智能体。
    5) 然而，对话式导航智能体识别出这其实是一个通用知识问题，而非导航请求，于是将该请求移交给通用知识智能体，由后者提供关于中央公园面积的事实信息。

- 协作模式（Collaborative Pattern）
  - 多个智能体在同一任务的互补方面并行工作，由“响应混合器智能体（Response Mixer Agent）”将不同响应的要点合成成一个完整答案。适用于：
    - 问题的不同方面需要不同类型的专长；
    - 单一智能体无法完整覆盖用户需求；
    - 用户受益于同一问题的多视角；
    - 专用智能体访问不同知识库或推理能力。
  - 与竞争模式不同，此处假定不同智能体的内容互补而非冗余，混合器负责提取最有价值的信息并综合成长文。

- 响应混合器智能体（Response Mixer Agent）
  - 专注于选择并融合多智能体响应中的最佳部分。依据准确性与相关性进行评估，剔除错误信息，合并不同响应的有用片段，为用户生成最有帮助的答案。
  - 示例交互略（关于“如何应对水上漂（aquaplaning）”的综合回答）。

- 自适应循环模式（Adaptive Loop Pattern）
  - 通过反复尝试与迭代改进，逐步提升结果直至满足目标标准。导航智能体可在初次搜索不理想时，自动重构查询：逐步放宽或转换条件，并返回最接近用户意图的结果，同时解释如何与初始请求相关。
  - 示例交互略（对餐馆搜索条件的迭代与扩展）。

多智能体架构对汽车 AI 的优势
- 角色专精：将复杂任务分解给多个专精智能体（如导航、媒体、车主手册），每个智能体在其领域形成更深能力。
- 效率与质量：狭窄任务更易优化，响应更快、质量更高、计算成本更低；对资源进行匹配：简单请求使用低算力，复杂问题使用更强资源。
- 速度与弹性：关键功能在设备端快速响应；非关键任务可用云端知识；掉线时关键控制仍正常运行。
- 系统韧性：断网时设备端功能可独立工作，保障基础体验。

Agent Builder
Vertex AI Agent Builder 是面向开发者的产品与服务集合，提供一个完整平台来构建与连接智能体，融合 Google Cloud 的工程卓越与安全、Google DeepMind 的 AI 研究与 AgentOps 的最佳实践。Google Cloud 正在将自家智能体构建在该平台之上，开发者也可以如此。预计 2025 年将有更多面向智能体开发者的精彩发布。
- Vertex AI Agent Engine：简化开发，依托 Google 管理的与流行开源智能体库的集成。提供托管自动扩缩的运行时，以及智能体所需的多种服务（如会话、示例、trace、evals）。这是一条低投入高价值的安全部署路径，支持以任何框架编写的智能体。
- Vertex AI Eval Service：提供本白皮书讨论的所有评估工具，以及更多。LLM、RAG 与智能体评估可通过 Vertex AI Eval Service 实现稳定与可扩展，并与监控与实验产品无缝整合。
- 丰富的智能体工具组合（示例）：
  - 检索：Vertex AI Search 或 RAG Engine
  - 非搜索型数据库检索：Gen AI Toolbox for Databases
  - 应用集成：数百个 API，支持完整 ACL
  - 将任何 API 变为托管的、企业就绪的工具：Apigee Hub
- 模型：访问 Vertex AI Model Garden 与 Gemini 系列模型，为智能体时代提供动力。

总结
本白皮书（作为先前《Agents》白皮书的伴随篇）探讨了生成式 AI 智能体快速演进的全景：从基本架构到高级评估技术，再到多智能体系统的变革潜力。

开发者关键要点：
1) AgentOps 至关重要：构建成功的智能体远不止 POC。践行 AgentOps 原则，融合 DevOps 与 MLOps 的最佳实践，并聚焦智能体特有的要素，如工具管理、编排、记忆与任务分解。
2) 指标驱动改进：以业务级 KPI（目标完成、用户参与、收入等）为“北极星”；为智能体埋点细粒度指标（关键任务、用户交互、智能体动作 trace）。人类反馈极其宝贵。
3) 自动化评估是关键：不要只靠手动测试。实现自动化评估框架以衡量智能体能力、轨迹与最终响应；采用精确/顺序/任意顺序匹配、精确率/召回率等评估轨迹；使用自动评审器（LLM 作为裁判）评估最终响应质量。
4) 人类参与不可或缺：自动指标很有力，但人类评估提供关键语境，尤其是创造力、常识与细微差异。用人类反馈校准并验证你的自动化评估方法。不要将领域知识外包。
5) 多智能体系统的优势：在复杂任务中考虑多智能体架构。它们可提升准确性、效率、可扩展性与容错性。理解不同设计模式（顺序、分层、协作、竞争），并为你的应用选择合适模式。
6) Agentic RAG 提升相关性：超越传统 RAG，引入主动优化查询、评估检索信息并适应演化知识的智能体，从而获得更准确与更具上下文的响应。
7) 搜索优化是 RAG 的地基：在深入 Agentic RAG 之前优化底层搜索：语义切片、元数据增强、嵌入模型微调、排序器等，能显著提升检索质量。
8) 智能体与工具注册表很重要：当智能体或工具数量增长，管理其能力、本体与绩效的注册表成为刚需。
9) 安全为上：在企业中部署智能体时务必优先安全。利用如 Google Agentspace 等平台的内置安全特性（RBAC、VPC Service Controls、IAM 集成）。
10) 开发者效率：在快速演进的智能体行业中审慎权衡“自建 vs 购买”。考虑平台与产品以避免从零开始的负担，使你聚焦数据、领域与用户。
11) 企业中的智能体：智能体正在改变我们的工作方式与自动化方式。知识工作者将越来越多地管理“智能体编队”，新的 UX 将涌现。Google Agentspace 是一个强有力的工具，可将企业搜索、AI 与 AI 智能体覆盖在公司的数据与工作流之上。

智能体研发的未来方向：
- 高级评估方法：更健壮与可扩展的评估，包括过程导向（聚焦推理）、AI 辅助评估与标准化基准。
- 多智能体协调：改进多智能体系统中的协调与通信机制，以实现更有效的协作、任务处理与推理。
- 真实世界适应：打造能在动态、不可预测的真实环境中适应与学习的智能体。汽车 AI 等生产系统强调在关键功能上通过设备端性能保证响应，同时在复杂任务上使用云端能力，并适应网络连接变化。
- 可解释性与可理解性：提升智能体行为的透明度与可理解性，让开发者与用户深入理解其决策过程。
- 长期记忆与持续学习：发展更复杂的记忆机制，使智能体在更长时间跨度内保留与使用信息，实现持续学习与适应。
- 智能体通信协议：更好地定义智能体如何共享任务、知识与消息，尤其是跨不透明的远程系统。
- 从智能体到承包商：要将智能体的可靠性与实用性提升到新水平，需要将任务定义提升为“合同”，具备明确交付物、验证机制与关于歧义的谈判能力，类似我们在现实世界中与其他公司签订合同。

行动号召：
AI 的未来是智能体化。鼓励开发者拥抱这些概念，开始构建下一代智能应用。试验本白皮书讨论的工具与技术；探索 Google Agentspace、NotebookLM Enterprise、Vertex Eval Service、Cloud Observability 与 Vertex AI Search 等资源以加速开发；研读代码示例、教程与文档并进行上手实践；构建、评估、迭代，并为智能体开发者社区做出贡献。机遇无限，行动当下！特别地，可从参考文献中的代码与 Colab 笔记本入手。

参考文献（Endnotes）
1) Shafran, I., Cao, Y. et al., 2022, “ReAct: Synergizing Reasoning and Acting in Language Models”. https://arxiv.org/abs/2210.03629
2) Wei, J., Wang, X. et al., 2023, “Chain-of-Thought Prompting Elicits Reasoning in Large Language Models”. https://arxiv.org/pdf/2201.11903.pdf
3) Wang, X. et al., 2022, “Self-Consistency Improves Chain of Thought Reasoning in Language Models”. https://arxiv.org/abs/2203.11171
4) Diao, S. et al., 2023, “Active Prompting with Chain-of-Thought for Large Language Models”. https://arxiv.org/pdf/2302.12246.pdf
5) Zhang, H. et al., 2023, “Multimodal Chain-of-Thought Reasoning in Language Models”. https://arxiv.org/abs/2302.00923
6) Yao, S. et al., 2023, “Tree of Thoughts: Deliberate Problem Solving with Large Language Models”. https://arxiv.org/abs/2305.10601
7) Long, X., 2023, “Large Language Model Guided Tree-of-Thought”. https://arxiv.org/abs/2305.08291
8) Google. “Google Gemini Application”. http://gemini.google.com
9) Swagger. “OpenAPI Specification”. https://swagger.io/specification/
10) Xie, M., 2022, “How does in-context learning work? ...”. https://ai.stanford.edu/blog/understanding-incontext/
11) Google Research. “ScaNN (Scalable Nearest Neighbors)”. https://github.com/google-research/google-research/tree/master/scann
12) LangChain. “LangChain”. https://python.langchain.com/v0.2/docs/introduction/
13) Sokratis Kartakis, 2024, “GenAI in Production: MLOps or GenAIOps?”. https://medium.com/google-cloud/genai-in-production-mlops-or-genaiops-25691c9becd0
14) Sokratis Kartakis, 2024, “Gen AI Ops, Operationalize Generative AI, A practical Guide”. https://medium.com/google-cloud/genaiops-operationalize-generative-ai-a-practical-guide-d5bedaa59d78
15) Cloud Trace overview. https://cloud.google.com/trace/docs/overview
16) Berkeley Function-Calling Leaderboard (BFCL). https://gorilla.cs.berkeley.edu/blogs/8_berkeley_function_calling_leaderboard.html
17) Karthik Narasimhan, et al. 2024, “τ-bench”. https://arxiv.org/abs/2406.12045
18) Karthik Valmeekam, et al., 2023, “PlanBench”. https://arxiv.org/abs/2206.10498
19) Xiao Liu, et al., 2023, “AgentBench”. https://arxiv.org/abs/2308.03688
20) Martin Iglesias, et al., 2025, “DABStep”. https://huggingface.co/spaces/adyen/DABstep
21) LangSmith platform for agent observability. https://docs.smith.langchain.com/evaluation/concepts#agents
22) Mingchen Zhuge, et al., 2024, “Agent-as-a-Judge: Evaluate Agents with Agents”. https://arxiv.org/abs/2410.10934
23) Multi-agent documentation from LangGraph. https://langchain-ai.github.io/langgraph/concepts/multi_agent/
24) LangChain blog 2024, “Multi-agent workflows”. https://blog.langchain.dev/langgraph-multi-agent-workflows/
25) Vectorize blog 2024, “How I finally got agentic RAG to work right”. https://vectorize.io/how-i-finally-got-agentic-rag-to-work-right/
26) Vertex AI Search docs. https://cloud.google.com/enterprise-search
27) Vertex AI Search Builder APIs docs. https://cloud.google.com/generative-ai-app-builder/docs/builder-apis
28) Vertex AI RAG Engine docs. https://cloud.google.com/vertex-ai/generative-ai/docs/rag-overview
29) Agentspace product docs. https://cloud.google.com/agentspace/agentspace-enterprise/docs/overview
30) NotebookLM Enterprise product docs. https://cloud.google.com/agentspace/notebooklm-enterprise/docs/overview
31) Juraj Gottweis, et al., 2025, “Accelerating scientific breakthroughs with an AI co-scientist”. https://research.google/blog/accelerating-scientific-breakthroughs-with-an-ai-co-scientist/
32) Hamsa Buvaraghan, et al. 2025, “Announcing public beta of Gen AI Toolbox for Databases”. https://cloud.google.com/blog/products/ai-machine-learning/announcing-gen-ai-toolbox-for-databases-get-started-today?e=48754805
33) Google Cloud Integration Connectors docs. https://cloud.google.com/integration-connectors/docs
34) Apigee API Hub docs. https://cloud.google.com/apigee/docs/apihub/what-is-api-hub
35) Vertex AI Model Garden docs. https://cloud.google.com/model-garden
36) Gemini family of LLMs docs. https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-models
37) Get Started Evaluating Agents with the Vertex Eval Service. https://cloud.google.com/vertex-ai/generative-ai/docs/models/evaluation-agents
38) Irina Sigler, Ivan Nardini. Jan 2025 “Introducing Agent Evaluation in Vertex AI”. https://cloud.google.com/blog/products/ai-machine-learning/introducing-agent-evaluation-in-vertex-ai-gen-ai-evaluation-service?e=48754805
39) Sample agent evaluation notebooks for LangGraph, CrewAI, LangChain. https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/evaluation/
40) Sample agents (beginner & intermediate). https://github.com/GoogleCloudPlatform/generative-ai/
41) Sample agents (intermediate & advanced). https://github.com/GoogleCloudPlatform/applied-ai-engineering-samples
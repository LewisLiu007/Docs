智能体导论与架构（Introduction to Agents and Agent architectures）
作者：Alan Blount, Antonio Gulli, Shubham Saboo, Michael Zimmermann, Vladimir Vuskovic

版本：2025年11月

致谢
- 内容贡献者：Enrique Chan, Mike Clark, Derek Egan, Anant Nawalgaria, Kanchana Patlolla, Julia Wiesinger
- 策展与编辑：Anant Nawalgaria, Kanchana Patlolla
- 设计师：Michael Lanning

目录
- 从预测式 AI 到自主智能体
- AI 智能体简介
- 智能体式问题求解过程
- 智能体系统的分级分类
  - 等级 0：核心推理系统
  - 等级 1：互联的解题者
  - 等级 2：策略型解题者
  - 等级 3：协作型多智能体系统
  - 等级 4：自我进化系统
- 核心架构：模型、工具与编排
  - 模型：智能体的“大脑”
  - 工具：智能体的“手”
  - 信息检索：让答案扎根现实
  - 执行动作：改变世界
  - 函数调用：将工具连接到智能体
  - 编排层
- 核心设计选择
  - 用领域知识与人格进行指令化
  - 用上下文进行增强
  - 多智能体系统与设计模式
- 智能体的部署与服务
- Agent Ops：将不确定变为有序的工程化方法
  - 像 A/B 实验一样衡量成功：埋点与度量
  - 质量而非通过/失败：使用“LM 评审”
  - 度量驱动开发：上线的 Go/No-Go
  - 用 OpenTelemetry Trace 调试：回答“为何如此？”
  - 重视人类反馈：引导自动化
- 智能体互操作
  - 智能体与人
  - 智能体与智能体
  - 智能体与金钱
- 单一智能体的安全：信任-能力权衡
  - 智能体身份：一种新的主体
  - 通过策略约束访问
  - 保护一个 ADK 智能体
- 从单体到企业“智能体舰队”的扩展
  - 安全与隐私：加固智能体前沿
  - 智能体治理：以控制平面替代扩张失控
  - 成本与可靠性：基础设施底座
- 智能体如何演化与学习
  - 智能体如何学习与自我进化
  - 仿真与 Agent Gym：下一前沿
- 高级智能体示例
  - Google Co-Scientist（共科学家）
  - AlphaEvolve Agent
- 结论
- 参考文献（Endnotes）

从预测式 AI 到自主智能体
多年来，AI 的焦点一直是擅长被动、离散任务的模型：回答问题、翻译文本，或根据提示生成图像。这种范式虽强大，但每一步都需要人类持续指挥。如今，我们正经历从“只预测或生成内容”的 AI，迁移到“能够自主解决问题与执行任务”的新型软件的范式转变。
这个新前沿围绕“AI 智能体”构建。智能体不仅仅是放在静态工作流中的一个 AI 模型；它是一类完整应用，能够制定计划并采取行动以实现目标。它将大语言模型（LM）的推理能力与可执行能力相结合，能处理单一模型无法胜任的复杂多步任务。关键能力在于：智能体能独立工作，自主决定到达目标的下一步，而无需人类在每一步都进行引导。
本文件是一个五篇系列的第一篇，旨在为从 POC 走向健壮的生产级智能体系统的开发者、架构师与产品负责人提供正式指南。虽然搭建一个简单原型很直接，但确保安全、质量与可靠性是一项重大挑战。本文提供系统性基础：
- 核心剖析：将智能体拆解为三个关键组成：推理的模型（Model）、可行动的工具（Tools）、与主持治理的编排层（Orchestration）。
- 能力谱系：从简单的互联解题者到复杂的协作多智能体系统的分级分类。
- 架构设计：针对每个组件的实用设计考量，从模型选型到工具实现。
- 生产化建设：建立 Agent Ops 学科，以评估、调试、安全加固与规模化，从单实例走向具备企业治理的舰队。
基于此前的《Agents》白皮书与《Agents Companion》，本文提供构建、部署与管理新一代“能推理、能行动、能观察以达成目标”的智能应用所需的核心概念与策略框架。

AI 智能体简介
人类与 AI 的交互语言不够精确。我们往往拟人化地使用“思考”“推理”“知道”等词。我们还没有准确区分“语义层面的知道”与“以最大化奖励概率为导向的知道”。二者是不同类型的“知道”，但在 99.X% 的时候结果相同。
以最简方式定义：AI 智能体由“模型、工具、编排层与运行时服务”的组合构成，并在一个循环中利用 LM 去完成目标。这四要素是任何自主系统的基本架构：
- 模型（大脑）：作为中央推理引擎的大语言模型或基础模型，用于处理信息、评估选项并作出决策。模型类型（通用、微调、或多模态）决定智能体的认知能力。智能体系统本质上是在精心策划放入 LM 上下文窗口的输入。
- 工具（双手）：将智能体的推理连接到外部世界，使其能力超越文本生成。它们包括 API 扩展、代码函数、以及用于访问实时事实信息的数据存储（如数据库、向量库）。智能体系统让 LM 规划要用的工具、执行工具、并将工具结果放入下一次 LM 调用的上下文窗口。
- 编排层（神经系统）：管理智能体运行循环的治理过程，负责规划、记忆（状态）与推理策略的执行。它运用提示框架与推理技术（如 CoT、ReAct）将复杂目标分解为步骤并决定何时“思考”与何时“用工具”。此层也为智能体提供“记忆”的能力。
- 部署（身体与双腿）：在笔记本上构建智能体适合原型期，而生产部署才能让其成为可靠可用的服务。这包括将智能体托管在安全、可扩展的服务器上，并集成监控、日志与管理等生产服务。部署后，用户可通过 UI 使用，或其他智能体可通过智能体到智能体（A2A）API 以编程方式调用。
归根结底，构建生成式 AI 智能体是开发解决任务的新方式。传统开发者像“砌砖工”，需要精确定义每一个逻辑步骤；智能体开发者更像“导演”。你不再为每个动作写死代码，而是设定“场景”（指引性指令与提示）、挑选“演员”（工具与 API）、并提供必要“上下文”（数据）。核心任务变为“引导演员（自主体）按预期表现”。
LM 的最大优点——灵活性，也常是最大头痛。LM 能做“很多事”，但很难让它稳定而完美地只做“一件特定事”。从“提示工程”演进到“上下文工程”，就是用指令、事实、可调用工具、示例、会话历史、用户画像等恰当地填充上下文窗口，得到所需输出。智能体即是为管理 LM 输入而生的软件。
当出现问题时，调试至关重要。Agent Ops 重新定义了“度量-分析-优化”的熟悉循环。通过 trace 与日志，你能观察智能体的“思考过程”，定位与预期路径的偏差。随着模型演进与框架改进，开发者的角色是提供关键要素：领域专长、明确的人格（Persona）、以及与工具的平滑集成。要牢记，全面的评估与测量往往比最初的系统提示更重要。
当一个智能体具有清晰的指令、可靠的工具、可作为记忆的上下文、良好的 UI、规划与解题能力，以及通用世界知识，它就超越了“工作流自动化”，成为一种协作实体：高效、可塑、且实力不凡的新团队成员。
本质上，智能体是专注于“上下文窗口策展”的系统。它不懈地循环：组装上下文、提示模型、观察结果、再为下一步重组上下文。上下文可能包含系统指令、用户输入、会话历史、长期记忆、来自权威来源的扎根知识、可用工具以及已调用工具的结果。对模型注意力的这种精细管理，让其推理在新情境下完成目标。

智能体式问题求解过程
我们将 AI 智能体定义为“围绕目标的完整应用”，集成推理模型、可行动工具与治理编排层。简化表述就是“LM + 工具，在循环中达成目标”。
那么，它具体如何工作？智能体从接收请求到交付结果，会经历什么？
智能体为实现目标运行一个持续的循环过程。虽然可变得相当复杂，但可拆解为五个基本步骤（详见《Agentic System Design》）：
1) 接收使命（Get the Mission）：由某个高层目标触发。使命可能来自用户（如“为我们团队安排即将到来的大会差旅”），也可能来自自动触发器（如“有一个高优先级的客户工单新到达”）。
2) 扫描场景（Scan the Scene）：感知环境并收集上下文。编排层会访问可用资源：用户请求说了什么？我在短期记忆中有什么？我之前尝试过这任务吗？用户上周给过指引吗？我可访问哪些工具（如日历、数据库、API）？
3) 深入思考（Think It Through）：这是由推理模型驱动的核心“思考”回路。智能体把使命（第 1 步）与场景（第 2 步）进行对照，制定计划。通常不是“一念”，而是一串推理链：“订差旅前，我先要知道团队成员。我会用 get_team_roster 工具。然后需要通过 calendar_api 查看他们的空闲时间。”
4) 采取行动（Take Action）：编排层执行计划的第一个具体步骤。选择并调用恰当的工具——调用 API、运行代码函数、或查询数据库。这是智能体将影响力施加到外部世界的时刻。
5) 观察并迭代（Observe and Iterate）：观察行动的结果。get_team_roster 工具返回五个名字。新的信息被加入上下文或“记忆”。循环回到第 3 步：“我已有名单，下一步查看这五个人的日历。我将使用 calendar_api。”
“思考-行动-观察”的循环持续进行——由编排层管理、由模型推理、由工具执行——直至完成内部计划、达成最初的使命。
客户支持智能体的现实例子（5 步循环）：
用户提问：“我的订单 #12345 在哪里？”
智能体先进入“深入思考”阶段，制定完整策略并推理：
“用户需要配送状态。要给出完整答案，我需要一个多步计划：
1. 识别：先在内部数据库找到订单，确认其存在并获取详情；
2. 追踪：从详情中提取承运商的运单号码，然后调用承运商的外部 API 获取实时状态；
3. 报告：将信息综合为清晰、有用的用户答复。”
带着这个多步计划，智能体开始执行。
第一次“行动”，它调用 find_order("12345") 工具。它“观察”到结果——完整订单记录，包括运单号 “ZYX987”。
编排层识别第一个部分已完成，立即进入第二部分。它调用 get_shipping_status("ZYX987") 工具。观察到新结果：“正在派送（Out for Delivery）”。
最后，当数据收集阶段成功执行，智能体进入“报告”步骤。它判定组成部分齐备，制定最终消息，并行动生成响应：“你的订单 #12345 正在派送中（Out for Delivery）！”

智能体系统的分级分类
理解 5 步运行循环是一部分；另一部分是认识到该循环的复杂度可扩展，从而形成不同类别的智能体。对架构师或产品负责人而言，一个关键早期决策是明确要构建的智能体类型。
我们可将智能体系统大致分为若干等级，每一级构建在前一等级能力之上。

等级 0：核心推理系统
在成为智能体之前，先从“大脑”的最基本形态开始：推理引擎本身。此时，LM 完全孤立运行，不使用任何工具、记忆或与实时环境交互。
优点来自大规模训练，可深入解释既有概念、并规划解题思路。权衡在于缺少实时感知；它对训练数据之外的事件或事实“盲目”。
例如，它能解释职业棒球规则与纽约洋基队的完整历史。但如果问“昨晚洋基队比赛的最终比分是多少？”，它将无法回答，因为那是训练数据之后发生的具体事件。

等级 1：互联的解题者
此等级将推理引擎与外部工具连接，变为可用的智能体——即架构中的“手”。它的解题不再局限于静态的预训练知识。
运用 5 步循环，智能体现在可以回答“昨晚洋基队比赛的比分”。“使命”为“昨晚洋基队比赛最终比分是多少？”，智能体在“思考”步骤识别到需要实时数据；“行动”步骤调用如 Google Search API 的工具（附日期与检索词）；“观察”到搜索结果（如“洋基 5-3 获胜”），并将其综合进最终答案。这种与世界互动（搜索比分、金融 API 获取实时股价、或经 RAG 访问数据库）的基础能力，是 1 级智能体的核心。

等级 2：策略型解题者
2 级显著扩展能力，从执行简单任务进化为策略性规划复杂的多部分目标。关键技能是“上下文工程”：智能体能够为计划的每一步主动选择、打包与管理最相关的信息。
智能体的准确性依赖于聚焦且高质量的上下文。上下文工程要在有限的模型注意力中策展最有用内容，避免过载并确保效率。
例如，“使命”为“帮我找一家在我办公室（1600 Amphitheatre Pkwy, Mountain View）与客户办公室（1 Market St, San Francisco）之间的中途‘好喝’咖啡店。”
2 级智能体会制定计划：
1. 思考：“我先要找到中点。”
   - 行动：用地图工具查询两个地址；
   - 观察：“中点是加州 Millbrae。”
2. 思考：“接着在 Millbrae 找咖啡店。用户说‘好’，我将筛选评分 ≥4.0 的店。”
   - 行动：调用 google_places，query="coffee shop in Millbrae, CA", min_rating=4.0。（这就是上下文工程——用上一步输出自动构造新且聚焦的查询）
   - 观察：“结果有‘Millbrae Coffee’与‘The Daily Grind’。”
3. 思考：“我将综合结果呈现给用户。”
策略规划还支持主动协助，例如阅读长航班确认邮件、抽取关键信息（航班号、日期），并将其添加到你的日历中。

等级 3：协作型多智能体系统
在这一最高等级（当前实践的高阶），范式发生根本变化：从构建一个全能“超级智能体”转向“专家团队协作”，类似于人类组织结构。系统合力来自于分工。
此处，智能体把其他智能体视作“工具”。设想“项目经理智能体”接收使命：“发布我们的‘Solaris’降噪耳机。”
项目经理智能体不会独自完成所有工作。它会像现实世界一样，行动去为团队中的专用智能体创建新使命，并委派任务：
1) 委派给 MarketResearchAgent：“分析降噪耳机的竞品定价。明天前返回摘要文档。”
2) 委派给 MarketingAgent：“基于‘Solaris’产品规格，拟三版新闻稿。”
3) 委派给 WebDevAgent：“基于附带设计稿生成新品页 HTML。”
这种协作模型虽然受限于当今 LM 的推理能力，但代表了“端到端自动化复杂业务流程”的前沿。

等级 4：自我进化系统
4 级从“委派”跃迁到“自主创造与适应”。此时，智能体系统能识别自身能力缺口，并动态创建新的工具甚至新的智能体来填补；从使用固定资源，进化到主动扩展资源。
沿用上述例子：项目经理智能体在推进“Solaris”发布时意识到需要监控社交媒体舆情，但团队中无此工具或智能体。
1) 思考（元推理）：“我必须追踪‘Solaris’的社媒热度，但我缺乏此能力。”
2) 行动（自主创建）：它调用高层的 AgentCreator 工具，设定新使命：“创建一个智能体，监控包含‘Solaris headphones’关键词的社媒，进行情感分析，并每日汇总报告。”
3) 观察：一个新的 SentimentAnalysisAgent 被创建、测试，并即时加入团队，为原始使命贡献力量。
这种能动态扩展自身能力的自主性，使一群智能体真正成为“会学习与演化的组织”。

核心架构：模型、工具与编排
我们已经知道智能体做什么，以及如何扩展。那么如何构建它？将概念落地为代码在于三个核心组件的具体架构设计。

模型：智能体的“大脑”
LM 是智能体的推理核心。模型选型是关键架构决策，决定智能体的认知能力、运行成本与速度。仅凭通用学术基准“最高分”选模型往往是失败路径；生产成功很少由抽象基准决定。
真实成功要求模型在智能体基本功上过硬：优秀的推理（驾驭复杂多步问题）与可靠的工具使用（与世界互动）。为此，从定义业务问题出发，用能直接映射到目标的指标测试模型：若智能体需要写代码，就在你的私有代码库上测；若处理保险理赔，就评估它在你的特定文档格式中抽取信息的能力；结合成本与延迟进行权衡。对你的任务而言，“最佳”模型位于质量-速度-价格的最优交点。
你也可选择多个模型组成“专家团队”。“不要用大锤砸核桃。”一个健壮架构可以用前沿模型（如 Gemini 2.5 Pro）承担初始规划与复杂推理的重负，然后将简单高频任务（如意图分类、摘要）智能路由到更快更省的模型（如 Gemini 2.5 Flash）。路由可自动或硬编码，这是优化性能与成本的关键策略。
对多样数据类型同理。原生多模态模型（如 Gemini live 模式）可简化图像/音频处理；替代方式是利用专门工具（Cloud Vision API、Speech-to-Text）先将世界转成文本，再交由文本 LM 推理。这带来灵活性与最优组件搭配，但也引入复杂度。
最后，AI 领域快速迭代，今天的模型 6 个月后会被更替。“一劳永逸”的心态不可持续。要为此现实构建“敏捷运营框架”——即 Agent Ops：建立 CI/CD，持续用关键业务指标评测新模型，降低升级风险、加速升级，使你的智能体始终由最佳“大脑”驱动，而无需推倒重来。

工具：智能体的“手”
若模型是“大脑”，工具就是将推理连接现实的“手”。它们让智能体超越静态训练数据，检索实时信息并对世界采取行动。健壮的工具接口是一个三段循环：定义工具能力、调用工具、观察结果。
常见工具大类（详见本系列工具专题白皮书）：
- 信息检索：让答案扎根现实（RAG）
  最基础工具是访问最新信息的能力。RAG 为智能体提供“借书证”，查询外部知识（向量数据库/知识图谱），源自内部文档到通过 Google 搜索访问的网页知识。对结构化数据，NL2SQL 允许智能体用自然语言查询数据库以回答“上季度最畅销产品是什么？”之类问题。先查再答（不论在文档还是数据库中），让智能体的答案扎根在事实，显著减少幻觉。
- 执行动作：改变世界
  真正的力量在于从“读信息”跨越到“做事情”。将现有 API 与代码函数包装为工具，智能体就能发邮件、约会议、或在 ServiceNow 更新客户记录。对更动态任务，智能体可现写现跑代码：在安全沙箱中生成 SQL 或 Python 来解决复杂问题或计算，从“知识助手”转变为“自主行动者”。
- 人类互动工具（HITL）
  智能体可以调用“人类在环”工具暂停流程，请求确认（如 ask_for_confirmation()）或从 UI 请求特定输入（如 ask_for_date_input()），确保关键决策有人参与。HITL 可用短信与数据库任务来实现。

函数调用：将工具连接到智能体
要让智能体稳定地进行函数调用与工具使用，需要清晰指令、安全连接与编排。久经考验的 OpenAPI 规范可提供结构化契约：描述工具目的、所需参数与预期响应。该模式让模型稳定生成正确调用并解释 API 返回。为简化发现与连接，开放标准如 MCP 流行起来（更便利）。此外，也有模型内置工具（如 Gemini 原生 Google Search），函数调用发生在 LM 调用内部。

编排层
若模型是“大脑”、工具是“手”，编排层就是连接二者的“中枢神经”。它运行“思考-行动-观察”循环，是治理智能体行为的状态机，也是开发者精心逻辑落地之处。这不只是“管道”，而是整场“智能体交响乐”的指挥：决定何时推理、选哪个工具行动、如何将行动结果引导下一步。
核心设计选择
第一项架构决策是确定智能体的自主程度。它存在一个光谱：一端是确定性的可预测工作流，只在特定点调用 LM 作工具；另一端是 LM 掌舵，动态适配、规划并执行任务达成目标。
并行的选择是实现方式。No-code 提供速度与易用性，让业务人员自动化结构化任务并快速搭建简单智能体。对更复杂且关键的系统，代码优先框架（如 Google 的 ADK）提供工程师需要的深度控制、定制化与集成能力。
无论哪种方法，生产级框架都是必要的：它需开放，允许插拔任何模型或工具避免厂商锁定；需具备精确控制，支持“LM 的非确定性推理”受硬编码业务规则治理；更重要是可观测性：当智能体表现异常时，你不能在模型“思考”里打断点。健壮框架应产出详尽 trace 与日志，暴露完整推理轨迹：模型的内部独白、所选工具、生成的参数与观察到的结果。
- 用领域知识与人格进行指令化
  在框架内，最强杠杆是用领域知识与明确人格（Persona）给智能体下达系统提示或核心指令。这不是一句话命令，而是“智能体宪法”：例如“你是 Acme Corp 的乐于助人的客服……”并明确约束、期望的输出结构、交互规则、语气风格、以及“何时/为何”使用工具。几条示例场景常常非常有效。
- 用上下文进行增强
  智能体“记忆”在运行时被组织进 LM 的上下文窗口（详见本系列“记忆”专题白皮书）。短期记忆是活跃的“草稿本”，维护当前对话的运行历史，跟踪进行中的（行动, 观察）对；可实现为 state、artifacts、session 或 thread 等抽象。长期记忆提供跨会话持久性，几乎总以一个专门工具的形式实现——连接向量库或搜索引擎的 RAG 系统。编排器赋予智能体预取与自查询历史的能力，使其“记住”用户偏好或周前类似任务的结果，带来个性化与连续体验。
- 多智能体系统与设计模式
  随着任务复杂度升高，构建一个全能“超级智能体”变得低效。更有效的方案是“专家团队”——这正是多智能体系统的核心：将复杂流程分解为离散子任务，各自分配给专用智能体。分工让每个智能体更简单、更聚焦、更易构建/测试/维护，尤其适用于动态或长时业务流程。
  业界可借鉴已验证的设计模式（能力快速演进中）。对动态或非线性任务，“协调者（Coordinator）”模式关键：引入“经理”智能体分析复杂请求，切分主任务，并将子任务智能路由至相应专家（如研究、写作、编码），再聚合各专家回复形成完整答案。
  对线性工作流，“顺序（Sequential）”模式更合适，像数字装配线，上一个智能体的输出作为下一个的输入。围绕质量与安全的模式还包括“迭代精炼（Iterative Refinement）”：用“生成器”产生内容、用“批评者”按质量标准评估并形成反馈回路；在高风险任务中，“人类在环（HITL）”模式至关重要：在关键动作前刻意暂停以征求人类批准。

智能体的部署与服务
当你构建完一个本地智能体，接下来会部署到服务器，使其常驻运行并供他人或其他智能体使用。继续类比，部署与服务就是“身体与双腿”。一个智能体要有效需具备若干服务：会话历史、记忆持久化等。作为构建者，你还需决定记录什么日志、采用何种安全措施（数据隐私、驻留与合规）。这些都在生产部署范围内。
幸运的是，能复用数十年的应用托管基础设施。智能体毕竟是新形态的软件，许多原则通用。构建者可以使用专门为智能体打造的部署选项，如 Vertex AI Agent Engine 提供一体化运行时与配套服务。若你希望更直接控制应用栈，或将智能体部署在既有 DevOps 基础上，也可将智能体与其服务打包为 Docker 容器，部署于 Cloud Run 或 GKE 等标准运行时。
如果你并非软件或 DevOps 专家，首次部署可能压力不小。许多框架提供便捷的 deploy 命令或专用平台，适合早期探索与上手。从试用过渡到安全、生产就绪的环境通常需要更多时间投入与最佳实践（包括 CI/CD 与自动化测试）。

Agent Ops：将不确定变为有序的工程化方法
你在构建第一个智能体时，会反复手动测试其行为：加了功能是否可用？修 bug 是否引入其它问题？软件开发中测试很常见，但在生成式 AI 中方式不同。
从传统确定性软件到随机性的智能体系统，需要全新运维哲学。传统单元测试断言 output == expected；但对本质概率化的智能体响应不适用。同时，语言的复杂性常要求用 LM 来评估“质量”：响应是否满足应做之事、不做不该做之事、且语气得当。
Agent Ops 是管理新现实的纪律化方法，是 DevOps 与 MLOps 的自然演进，面向构建、部署与治理 AI 智能体的独特挑战，将不可预测性由负担变为可管理、可度量且可靠的特性。（详见本系列“质量”专题白皮书）
- 像 A/B 实验一样衡量成功：埋点与度量
  在改进前，先定义对业务而言“更好”的含义。将可观测性策略框定为 A/B 实验，问自己：哪些 KPI 证明智能体在交付价值？这些指标要超越技术正确性，衡量真实影响：目标完成率、用户满意度、任务延迟、交互单位成本，尤其是对收入、转化、留存等业务目标的影响。自上而下的视角将引导余下测试，指向“度量驱动开发”，并让你可计算 ROI。
- 质量而非通过/失败：使用“LM 评审”
  业务指标无法证明智能体“行为正确”。由于无法二元通过/失败，我们转向用“LM 作为裁判（LM-as-Judge）”评估质量：用强模型依据预设评分量表评测输出：是否正确？是否基于事实？是否遵循指令？将其跑在“黄金数据集”上，得到一致的质量度量。
  构建评估数据集（理想提问与正确答复）会略显繁琐。应从现有生产或开发交互中抽样，覆盖期望范围外加少数意外场景。尽管评估投入很快回本，但评估结果在被接受为有效前应由领域专家复核。越来越多地，策划与维护评估集成为产品经理在领域专家支持下的重要职责。
- 度量驱动开发：上线的 Go/No-Go
  当你自动化了数十个评估场景并建立可信质量分数，就能自信测试开发版变更：用新版本跑完整评估集，与线上版本直接对比分数，消除拍脑袋上线。除自动评估外，别忘了延迟、成本、任务成功率等指标。为最大安全性，采用 A/B 灰度发布，在真实生产指标与模拟评分并行对比下推进。
- 用 OpenTelemetry Trace 调试：回答“为何如此？”
  当指标下降或用户报错，你需要理解“为什么”。OpenTelemetry trace 是智能体完整执行路径（轨迹）的高保真逐步记录，支持按步骤调试。借助 trace，你可看到发给模型的确切提示、模型的内部推理（若可用）、所选工具、生成的工具参数与返回的原始数据。第一次看 trace 可能复杂，但它提供了诊断与定位根因所需的细节。重要 trace 细节可转化为指标，但审阅 trace 主要用于调试而非总体趋势。Google Cloud Trace 等平台可可视化与检索大量 trace，简化根因分析。
- 重视人类反馈：引导自动化
  人类反馈不是麻烦，而是改进智能体最有价值、数据最丰富的资源。当用户报 bug 或点“踩”，他们提供了“黄金礼物”：评估场景未覆盖的真实边界案例。收集与聚合此类数据非常关键；当出现显著数量的相似报告或指标回落，应将这些事件与分析平台关联，以生成洞察并触发运维告警。有效的 Agent Ops 会“闭环”：捕获反馈、复现问题、并将该具体场景转化为新且永久的评估用例。这确保你不仅修复 bug，还“为该类错误接种疫苗”。

智能体互操作
当你构建出高质量智能体后，需要将它们与用户及其他智能体互联。继续类比，这相当于“智能体的脸面”。连接“智能体”与“数据/APIs/工具”是两件事；智能体不是工具。假设你已经把工具织入智能体，下面考虑如何将智能体带入更广生态。
- 智能体与人
  最常见的人机交互是 UI。最简单是聊天框：用户输入请求，智能体作为后端服务处理并返回文本。更高级的智能体可输出结构化数据（如 JSON），驱动丰富的动态前端。HITL 人机交互包含意图澄清、目标扩展、确认与澄清请求。
  “Computer use”是一类工具，LM 接管用户界面，通常伴随人机互动与监督。具备该能力的智能体可决定下一步是跳转页面、点特定按钮、或预填表单。另一种方式不是“智能体替用户操作 UI”，而是“LM 动态改造 UI 以适应当下需求”：可通过 MCP UI 这样的工具控制 UI，或通过 AG UI 这类事件传递（可选共享状态）的专用 UI 消息系统，与甚至通过 A2UI 生成定制界面。
  人机交互不限于屏幕与键盘。高级智能体正突破文本，进入实时多模态的“live 模式”，带来更自然的人类式连接。Gemini Live API 等技术支持双向流式交互，用户可像自然对话般说话并打断智能体。
  拥有摄像头与麦克风访问权限，智能体可“所见即所得”，用生成语音以接近人类对话的延迟进行回应。这开启了文本不可及的用例：如维修技师在操作中获得免手的实时指导，或购物者得到实时穿搭建议，让智能体成为更直观可及的伙伴。
- 智能体与智能体
  随企业 AI 使用规模扩大，不同团队会构建不同的专用智能体。若无通用标准，连接它们将需要一团难以维护的脆弱自定义 API 集成。核心挑战有二：发现（我的智能体如何找到其他智能体、了解其能做什么？）与通信（如何确保它们说同一种语言？）。
  Agent-to-Agent（A2A）协议是为解决此问题设计的开放标准，充当“智能体经济”的通用握手。A2A 允许任何智能体发布“数字名片”（Agent Card）：一个简单 JSON 文件，声明能力、网络端点、与交互所需的安全凭据，使发现简单且标准化。与专注事务请求的 MCP 不同，A2A 更侧重用于增量解题的智能体间通信。
  发现之后，智能体按照“以任务为中心”的架构进行通信。互动不是简单“请求-响应”，而是异步“任务”：客户端智能体发送任务请求，服务端智能体在长连接上提供流式进度更新。这种稳健的标准化通信协议，补全了构建 3 级“协作多智能体系统”的最后拼图，将孤立个体化的智能体集合，转变为真正的可互操作生态。
- 智能体与金钱
  随着智能体为我们做更多事，其中一些涉及买卖、谈判或促成交易。当前的 Web 为“人点‘买’”设计，责任在于人；若“自主智能体”点了“买”，若出了问题，责任在谁？这涉及授权、真实性与问责的复杂议题。要解锁真正的“智能体经济”，需要新的标准，允许智能体代表用户安全可靠地进行交易。
  这一领域尚未成型，但两个关键协议在铺路。Agent Payments Protocol（AP2）旨在成为智能体商业的通用语言。它在 A2A 等协议之上引入“数字授权书（mandate）”，用加密签名构成可验证的用户意图证明，形成每笔交易“不可否认”的审计轨迹，允许智能体基于用户的委托在全球范围内安全浏览、谈判与交易。与之互补的 x402 是开放互联网支付协议，利用标准的 HTTP 402 “Payment Required”状态码，使机器对机器的小额支付无摩擦进行，如按次为 API 访问或数字内容付费，无需复杂账号或订阅。二者共同为“智能体 Web”构建信任底座。

单一智能体的安全：信任-能力权衡
创建首个 AI 智能体时，立刻会遇到基本张力：实用性与安全性的权衡。要让智能体有用，必须赋予它权力——自主决策与执行的工具（发邮件、查数据库等）；但每一分权力都带来相应风险，尤其是“越权行动”（无意或有害行为）与“敏感数据泄露”。要给它足够长的“绳子”以完成工作，但又要短到不至于“跑上马路”，尤其是涉及不可逆动作或公司的私密数据。
要管理这一点，不能只依赖 AI 模型的判断，因为它可被提示注入等技术操控。最佳实践是“深度防御”的混合方法：
- 第一层：传统确定性护栏——在模型推理之外的硬编码安全卡口。例如策略引擎限制：禁止超过 $100 的购买，或要求与外部 API 交互前必须获得用户明示确认。该层提供可预测、可审计的“硬限制”。
- 第二层：基于推理的防护——“用 AI 保护 AI”。包括对模型进行对抗训练以提升抗攻击性，以及使用小型专用“护卫模型”作为安全分析师：在执行前审查智能体提出的计划，标记潜在风险或违反策略的步骤，等待复核。将代码的刚性确定性与 AI 的语境感知相结合，即便对单一智能体也能构建健壮的安全态势，使其权力始终与使命保持一致。

智能体身份：一种新的主体
传统安全模型中有“人类用户”（用 OAuth/SSO）与“服务”（用 IAM/服务账号）。智能体引入第三类主体：它不仅是一段代码，而是一位自治行动者，需要可验证的独立身份。就像发给员工 ID 卡一样，平台上的每个智能体都必须发放安全可验证的“数字护照”。该“智能体身份”不同于调用者的用户身份，也不同于构建者的开发者身份。这对企业的身份与访问管理（IAM）是根本性改变。
让每个身份可验证并对其施加访问控制，是智能体安全的基石。一旦智能体有可加密验证的身份（如采纳 SPIFFE），即可授予“最小权限”的专属许可：SalesAgent 获得 CRM 的读写权限，而 HRonboardingAgent 被明确拒绝。这种细粒度控制至关重要：即便单个智能体被攻破或行为异常，潜在影响半径是受控的。没有“智能体身份”这个构造，智能体无法以有限授权代表人类工作。
（示意表）主体分类（节选）：
- 用户（OAuth/SSO 认证）：人类行为主体，对其行为承担全部责任
- 智能体（新主体，SPIFFE 验证）：受委托权限，代表用户采取行动
- 服务账号（集成到 IAM）：应用/容器，完全确定性，对行为负责的范式不同

通过策略约束访问
策略（Policy）属于授权（AuthZ），区别于认证（AuthN）。策略通常限制主体的能力；例如“市场部用户仅可访问这 27 个 API 端点，且不可执行 DELETE”。在开发智能体时，我们需要给智能体、工具、其他内部智能体、可共享的上下文、以及远程智能体施加权限。换个角度思考：当你把所有 API、数据、工具与智能体都接入系统后，必须将访问约束在“完成其工作所必需的子集”上。这就是推荐方式：在保持语境关联性的同时，贯彻“最小权限”原则。

保护一个 ADK 智能体
在明确身份与策略原则后，保护 ADK 构建的智能体就是把这些理念落实到代码与配置。流程包括：
- 明确身份边界：用户账号（如 OAuth）、服务账号（代码运行）、智能体身份（用于受委托授权）；
- 认证完成后，下一层是策略治理，约束对各类服务的访问，通常在 API 治理层执行，并对 MCP 与 A2A 服务做治理；
- 再下一层是在工具、模型与子智能体内建立“护栏”以强制策略：无论 LM 推理出什么，或恶意提示建议什么，工具自身的逻辑都要拒绝不安全或越权动作。该方式提供可预测且可审计的安全基线，将抽象安全策略转化为可依赖的代码。
为对智能体的运行时行为进行更动态的安全适配，ADK 提供回调与插件：before_tool_callback 可在工具执行前检查参数，结合当前状态验证并阻止不当行为；更可复用的策略可写成插件。常见模式是“Gemini 作为裁判”：用快速且廉价的模型（Gemini Flash-Lite 或你自训练的 Gemma）实时筛查用户输入与智能体输出中的提示注入或有害内容。
对倾向于采用全面托管的企业级动态检查的组织，可引入“Model Armor”作为可选服务：它作为专门安全层筛查提示与响应中的多类威胁（提示注入、越狱、敏感数据泄露、恶意 URL 等），将复杂安全任务卸给专职服务，确保一致且健壮的保护，而无需自行构建与维护护栏。ADK 的混合方案——强身份、确定性的工具内逻辑、AI 驱动的动态护栏，以及可选的托管安全服务——就是打造既强大又可信的单智能体之道。

从单体到企业“智能体舰队”的扩展
一个单智能体的生产成功固然可喜，将其扩展为数百规模的“智能体舰队”则是架构挑战。若只构建一两个智能体，关注点主要在安全；若要构建许多智能体，就必须设计系统来应对更复杂的情况。就像“API 蔓延”，当智能体与工具在组织内激增，会形成新的、复杂的交互网络、数据流与潜在安全漏洞。管理这种复杂性需要更高阶的治理层，将所有身份与策略整合到中心控制平面。
- 安全与隐私：加固智能体前沿
  即使仅运行单智能体，企业级平台也必须解决生成式 AI 的独特安全与隐私挑战。智能体本身成为新的攻击向量：恶意者可能尝试提示注入来劫持指令，或数据投毒来污染模型训练或 RAG 数据。此外，约束不当的智能体可能在响应中无意泄露敏感客户数据或专有信息。
  健壮平台需提供“纵深防御”策略：从数据层开始，确保企业专有数据绝不用于训练基础模型，并通过如 VPC Service Controls 的控制保护；需要输入/输出过滤，充当提示与响应的“防火墙”；最后提供合同保障，如对训练数据与生成输出的知识产权赔付，为企业在生产部署智能体提供法律与技术信心。
- 智能体治理：以控制平面替代扩张失控
  随智能体与工具在组织内激增，会出现新的复杂交互与潜在漏洞挑战，即“智能体蔓延”。管理它需要从“保护单个智能体”上升到“中心化架构”的方法：一个中央网关作为所有智能体活动的控制平面。
  设想一个拥有成千上万自治体（用户、智能体、工具）的都市。没有红绿灯、车牌与交通管制，必将混乱。网关方法即创造此管制系统：为所有智能体交通设立必经入口，包括用户到智能体的提示/UI 交互、智能体到工具的调用（经 MCP）、智能体到智能体的协作（经 A2A）、以及对 LM 的直接推理请求。位于这一关键路口，组织能检查、路由、监控与管理每次交互。
  控制平面有两个主职能：
  1) 运行时策略执行：在架构上形成安全卡口，处理认证（我认识这个行为体吗？）与授权（它有权限做此事吗？）。集中执行提供单视图可观测性，为每笔事务生成统一日志、指标与 trace，将“意大利面式”的分散智能体/工作流，转变为透明且可审计系统。
  2) 中央治理：要有效执行策略，网关需要真相源（SoT），即中央注册表——智能体与工具的“企业应用商店”。注册表让开发者发现与复用现有资产，避免重复建设，同时赋予管理员完整资产清单；更重要的是，它支持智能体与工具的正式生命周期：发布前的安全审查、版本化、以及针对不同业务单元的细粒度访问策略。
  将运行时网关与中央治理注册表结合，组织就能把混乱扩张的风险，转化为可管理、安全且高效的生态。
- 成本与可靠性：基础设施底座
  企业级智能体必须既可靠又具成本效益。频繁失败或响应缓慢的智能体带来负 ROI；过于昂贵的智能体无法规模化。底层基础设施必须为此权衡而设计，并满足安全、合规与数据主权要求。
  某些场景需要“按需启停（scale-to-zero）”，以应对特定智能体或子功能的间歇流量；对关键、延迟敏感的工作负载，平台需提供“容量保障”，如 LM 服务的 Provisioned Throughput 或 Cloud Run 99.9% SLA 等，为关键智能体提供可预测性能，确保在高负载下仍然响应。通过提供这条基础设施选项光谱，辅以全面的成本与性能监测，就构筑起将 AI 智能体从“创新亮点”扩展为“企业核心可靠组件”的最后基座。

智能体如何演化与学习
部署在真实世界的智能体运行于动态环境：策略、技术与数据格式持续变化。若无法适应，智能体性能会随时间下降（“老化”），导致实用性与信任流失。手工更新庞大舰队以追赶变化既不经济也慢。更可扩展的方案是设计“能自学与自进化”的智能体，以最小工程投入在岗位上持续提升质量。

智能体如何学习与自我进化
类似人类，智能体从经验与外部信号中学习。学习过程的燃料包括：
- 运行时经验：智能体从会话日志、trace 与记忆等运行产物学习，捕捉成功/失败、工具交互与决策轨迹。HITL 反馈尤为关键，提供权威纠正与指导。
- 外部信号：来自新发布的外部文档，如企业策略更新、公共监管指南、或其他智能体的批评/点评。
这些信息用于优化智能体的未来行为。高级系统不只是“总结过去”，而是产出可泛化的工件引导未来任务。最成功的适配技术大致分两类：
- 上下文工程增强：系统持续优化提示、Few-shot 示例与从记忆检索的信息，为每个任务提供最优上下文，提升成功率。
- 工具优化与创造：智能体的推理可识别能力缺口并采取行动填补：获得新工具访问、现场生成新工具（如 Python 脚本）、或修改既有工具（如更新 API 模式）。
此外还有其它优化，如动态重构多智能体设计模式或采用 RLHF 等，均是活跃研究方向。

示例：学习新的合规指南
设想在强监管行业（如金融/生命科学）运行的企业智能体，任务是生成必须符合隐私与监管（如 GDPR）的报告。
可用多智能体工作流实现：
1) “查询智能体”按用户请求检索原始数据；
2) “报告智能体”将数据综合为报告草稿；
3) “批评智能体”携带既定合规指南审阅报告；若有歧义或需最终签署，则升级给人类专家；
4) “学习智能体”观察整个交互，特别关注人类专家的纠正，然后将其泛化为新、可复用的规则（如更新批评智能体的规则或细化报告智能体的上下文）。
例如，若人类专家指出某些家庭统计必须匿名化，“学习智能体”记录该纠正。下次生成类似报告时，“批评智能体”将自动应用此新规则，减少人类干预。批评-人类反馈-泛化这一循环使系统能自适应演化的合规要求。

仿真与 Agent Gym：下一前沿
上述模式可归类为“在线内学习”（in-line），即智能体在其工程定义的资源与模式内学习。更先进的思路是研究“离线优化平台”——专门工程化的平台（Agent Gym），用于在离线流程中以丰富工具与能力来优化多智能体系统，这些能力不属于运行时环境。其关键属性：
1) 不在执行路径上：是独立的非生产平台，因此可使用任意 LM、离线工具、云应用等辅助；
2) 提供仿真环境：智能体可在新数据上“练习”并学习，非常适合多路径“试错”优化；
3) 可调用高级合成数据生成器，引导仿真尽可能逼真，并对智能体进行压力测试（包括红队化、动态评估与批评者家族等）；
4) 优化工具库不是固定的：可通过开放协议（MCP、A2A）接入新工具，或在更高级设定下学习新概念并围绕其“打造工具”；
5) 即便是 Agent Gym，也可能无法跨越某些“企业部落知识”导致的边界案例；此时，Gym 可连接人类领域专家网络，与之探讨目标产出，指导下一轮优化。

高级智能体示例
- Google Co-Scientist（共科学家）
  Co-Scientist 是一款高级 AI 智能体，作为虚拟研究合作者，通过系统化探索复杂问题空间来加速科学发现。研究者设定目标、指定公共与专有知识源为“扎根”，随后智能体生成并评估大量新颖假设。
  为实现此目标，Co-Scientist 会孵化一个协作的多智能体生态：如“主管”智能体充当管理者，向专用智能体团队委派任务与分配计算资源，使项目可轻松扩展并在推进中持续改进方法。各智能体运行数小时乃至数日，通过“循环与元循环”不断改进假设的产生方式与评判方式。
- AlphaEvolve Agent
  AlphaEvolve 是另一类高级系统的例子：它为数学与计算机科学中的复杂问题发现与优化算法。其方法结合了 Gemini 语言模型的创造性代码生成与自动化评估系统，采用“进化过程”：AI 生成候选解、评估器打分、最有前景的思路启发下一代代码。已经取得多项突破，包括：提升数据中心、芯片设计与 AI 训练效率；发现更快的矩阵乘法算法；找到开放数学问题的新解。AlphaEvolve 特别擅长“验证比求解更容易”的问题。
  它被设计为人机深度迭代的合作：AI 以“可读代码”形式输出方案，使用户理解逻辑、获得洞见、信任结果并按需直接修改；同时人类专家在定义问题上至关重要，通过优化评估指标与引导探索防止系统钻“定义漏洞”。交互循环确保最终方案兼具强大与实用。智能体的结果是代码持续迭代优化，不断提升人类指定的指标。

结论
生成式 AI 智能体是分水岭式的演进：将 AI 从被动的内容生成工具，转化为主动的、自主的解题伙伴。本文提供理解与构建这些系统的正式框架，从原型走向可靠的生产级架构。
我们将智能体拆解为三要素：推理模型（大脑）、可行动的工具（双手）与统领的编排层（神经系统）。正是这三者的无缝集成，在“思考-行动-观察”的连续循环中，释放智能体真正潜能。通过对智能体系统进行分级分类——从 1 级“互联解题者”到 3 级“协作多智能体系统”——架构师与产品负责人可按任务复杂度有的放矢地设定范围。
中心挑战与机遇在于新的开发范式：我们不再仅是“砌砖工”，而是“架构师/导演”，必须引导、约束并调试一个自治实体。让 LM 强大的灵活性成为生产中的可靠性，需要系统工程：健壮的工具契约、韧性的错误处理、复杂的上下文管理与全面的评估。本文的原则与架构模式为这片新前沿提供基础蓝图：它不是仅仅“自动化工作流”，而是构建协作、能干、可适应的“新队友”。随着技术成熟，这种纪律化的架构方法将决定我们能否真正驾驭智能体 AI 的全部力量。

参考文献（Endnotes）
1) Julia Wiesinger, Patrick Marlow, et al., 2024, “Agents”. https://www.kaggle.com/whitepaper-agents
2) Antonio Gulli, Lavi Nigam, et al., 2025, “Agents Companion”. https://www.kaggle.com/whitepaper-agent-companion
3) Shunyu Yao, et al., 2022, “ReAct: Synergizing Reasoning and Acting in Language Models”. https://arxiv.org/abs/2210.03629
4) J. Wei, X. Wang, et al., 2023, “Chain-of-Thought Prompting Elicits Reasoning in Large Language Models”. https://arxiv.org/pdf/2201.11903.pdf
5) Shunyu Yao, et al., 2022, “ReAct: Synergizing Reasoning and Acting in Language Models”. https://arxiv.org/abs/2210.03629
6) “Agentic Design Patterns: Hands-On Intelligent Systems”（图书链接）：https://www.amazon.com/Agentic-Design-Patterns-Hands-Intelligent/dp/3032014018
7) Shunyu Yao, et al., 2024, “τ-bench: A Benchmark for Tool-Agent-User Interaction in Real-World Domains”. https://arxiv.org/abs/2406.12045
8) https://artificialanalysis.ai/guide
9) https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/vertex-ai-model-optimizer
10) https://gemini.google/overview/gemini-live/
11) https://cloud.google.com/vision?e=48754805&hl=en
12) https://cloud.google.com/speech-to-text?e=48754805&hl=en
13) https://medium.com/google-cloud/genaiops-operationalize-generative-ai-a-practical-guide-d5bedaa59d78
14) https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/code-execution/overview
15) https://ai.google.dev/gemini-api/docs/function-calling
16) https://github.com/modelcontextprotocol/
17) https://ai.google.dev/gemini-api/docs/google-search
18) https://google.github.io/adk-docs/
19) https://google.github.io/adk-docs/sessions/memory/
20) https://cloud.google.com/architecture/choose-design-pattern-agentic-ai-system
21) https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/overview
22) https://cloud.google.com/kubernetes-engine/docs/concepts/gke-and-cloud-run
23) https://github.com/GoogleCloudPlatform/agent-starter-pack
24) Sokratis Kartakis, 2024, “GenAI in Production: MLOps or GenAIOps?”. https://medium.com/google-cloud/genai-in-production-mlops-or-genaiops-25691c9becd0
25) Guangya Liu, Sujay Solomon, 2025-03, “AI Agent Observability - Evolving Standards and Best Practice”. https://opentelemetry.io/blog/2025/ai-agent-observability/
26) https://discuss.google.dev/t/agents-are-not-tools/192812
27) Damien Masson, et al., 2024, “DirectGPT: A Direct Manipulation Interface to Interact with Large Language Models”. https://arxiv.org/abs/2310.03691
28) MCP UI（通过 MCP 工具控制 UI）：https://mcpui.dev/
29) AG UI（通过事件传递与可选共享状态控制 UI）：https://ag-ui.com/
30) A2UI（通过结构化输出与 A2A 消息生成 UI）：https://github.com/google/A2UI
31) https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/2-5-flash-live-api
32) https://saif.google/focus-on-agents
33) https://simonwillison.net/series/prompt-injection/
34) https://storage.googleapis.com/gweb-research2023-media/pubtools/1018686.pdf
35) https://spiffe.io/
36) https://openreview.net/pdf?id=l9rATNBB8Y
37) https://google.github.io/adk-docs/safety/
38) https://google.github.io/adk-docs/callbacks/design-patterns-and-best-practices/#guardrails-policy-enforcement
39) TKTK
40) https://cloud.google.com/security-command-center/docs/model-armor-overview
41) https://cloud.google.com/vertex-ai/generative-ai/docs/provisioned-throughput/overview
42) https://cloud.google.com/run/sla
43) https://github.com/CharlesQ9/Self-Evolving-Agents
44) Juraj Gottweis, et al., 2025, “Accelerating scientific breakthroughs with an AI co-scientist”. https://research.google/blog/accelerating-scientific-breakthroughs-with-an-ai-co-scientist/
45) Deepak Nathani, et al., 2025, “MLGym: A New Framework and Benchmark for Advancing AI Research Agents”. https://arxiv.org/abs/2502.14499